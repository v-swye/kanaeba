<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kanaeba&#39;s Long Position</title>
  
  <subtitle>Life is short, so be sure to go long.</subtitle>
  <link href="/kanaeba/atom.xml" rel="self"/>
  
  <link href="https://v-swye.github.io/kanaeba/"/>
  <updated>2020-01-19T09:55:59.935Z</updated>
  <id>https://v-swye.github.io/kanaeba/</id>
  
  <author>
    <name>Kanaeba</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LaTeX安装、vs code编译及宏包</title>
    <link href="https://v-swye.github.io/kanaeba/2020/01/18/LaTeX%E5%AE%89%E8%A3%85%E3%80%81vs%20code%E7%BC%96%E8%AF%91%E5%8F%8Abeamer%E4%BD%BF%E7%94%A8/"/>
    <id>https://v-swye.github.io/kanaeba/2020/01/18/LaTeX%E5%AE%89%E8%A3%85%E3%80%81vs%20code%E7%BC%96%E8%AF%91%E5%8F%8Abeamer%E4%BD%BF%E7%94%A8/</id>
    <published>2020-01-17T16:00:00.000Z</published>
    <updated>2020-01-19T09:55:59.935Z</updated>
    
    <content type="html"><![CDATA[<p>本文基于windows平台，主要是记录一下个人小白级别的安装流程，供有需的同学参考（这个有需的同学很有可能是x年后的自己XD）。</p><h2 id="安装LaTeX"><a href="#安装LaTeX" class="headerlink" title="安装LaTeX"></a>安装LaTeX</h2><p>首先下载TexLive，可以官网下载也可以到镜像网站下载，后者在国内速度更快。然后光驱加载下载的IOS文件，右键管理员运行Advanced执行文件，指定安装位置和安装包，可以去掉大多数不需要的语言包，然后静待安装完成，整个安装流程需要比较长的时间。</p><p>同时在vs code的扩展商店安装好LaTeX Workshop。<br>在TexLive安装完成后，到我的电脑【右击】 -&gt;属性 -&gt; 高级系统设置 -&gt; 环境变量中，选中path，点击编辑，然后新建tex的安装路径，以2019版默认安装路径为例，填入<code>C:\texlive\2019\bin\win32</code>.</p><p>在vs code中打开一个tex文件，<code>ctrl+alt+b</code>或者<code>ctrl+S</code>build编译，再<code>ctrl+alt+v</code>分屏浏览pdf输出结果，之后每次保存都会自动更新输出结果，非常方便~</p><h2 id="安装宏包"><a href="#安装宏包" class="headerlink" title="安装宏包"></a>安装宏包</h2><p>使用宏包时，我们在tex文档中加入<code>\usepackage[options]{}</code>，有些默认安装好的宏包可以直接使用。要使用其他未安装的宏包，首先管理员身份运行<code>tex live command-line</code>, 然后输入<code>tlmgr install packagename</code>，等待安装完成。如需更新<code>tlmgr</code>，按提示操作即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文基于windows平台，主要是记录一下个人小白级别的安装流程，供有需的同学参考（这个有需的同学很有可能是x年后的自己XD）。&lt;/p&gt;
&lt;h2 id=&quot;安装LaTeX&quot;&gt;&lt;a href=&quot;#安装LaTeX&quot; class=&quot;headerlink&quot; title=&quot;安装LaTe
      
    
    </summary>
    
    
      <category term="编程与技术" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="LaTeX" scheme="https://v-swye.github.io/kanaeba/tags/LaTeX/"/>
    
  </entry>
  
  <entry>
    <title>数据长宽转换：基于Python</title>
    <link href="https://v-swye.github.io/kanaeba/2019/12/03/%E6%95%B0%E6%8D%AE%E9%95%BF%E5%AE%BD%E8%BD%AC%E6%8D%A2%EF%BC%9A%E5%9F%BA%E4%BA%8EPandas/"/>
    <id>https://v-swye.github.io/kanaeba/2019/12/03/%E6%95%B0%E6%8D%AE%E9%95%BF%E5%AE%BD%E8%BD%AC%E6%8D%A2%EF%BC%9A%E5%9F%BA%E4%BA%8EPandas/</id>
    <published>2019-12-03T10:31:22.000Z</published>
    <updated>2019-12-03T14:17:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>在数据分析工作中，一个比较麻烦的问题便是从其他人习惯的“excel”表式的wide数据（宽数据）到适合计算机处理、分析、绘图的long格式数据（长数据）的转换。而输出时，一些项目也会对输出的格式提出要求，这就要求我们把长格式输出为宽格式。好在Pandas提供了简洁的数据长宽格式转换的方法。</p><h2 id="宽格式转换为长格式"><a href="#宽格式转换为长格式" class="headerlink" title="宽格式转换为长格式"></a>宽格式转换为长格式</h2><p>这里介绍pd.melt()函数将宽格式转换为长格式。这里仅演示较为简单的单层索引情况。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data_long = data_wide.melt(</span><br><span class="line">    id_vars= [<span class="string">'id1'</span>,<span class="string">'id2'</span>], </span><br><span class="line">    <span class="comment">#原宽型数据中要保留下来的索引，类似数据库中的一个键；每个条目只有id1和id2会维持不变</span></span><br><span class="line">    value_vars =  [<span class="string">'var1'</span>,<span class="string">'var2'</span>] ,<span class="comment">#需要拉长的分类变量，这几个变量列会在结果中合并成一列（下称分类列），列的值即是这几个变量的名称</span></span><br><span class="line">    var_name =<span class="string">'varname'</span>,  <span class="comment"># 上述分类列的列名，默认为variable</span></span><br><span class="line">    value_name = [<span class="string">'value1'</span>,<span class="string">'value2'</span>], <span class="comment">#在元数据中id1,id2对应的条目，var1和var2的实际取值（而非变量名称），在最终结果中被命名为value1和value2；默认会被命名为value</span></span><br><span class="line">    col_level = <span class="number">0</span>, <span class="comment">#在多层索引时，基于列索引的第一层索引进行格式转换</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><h2 id="长格式转宽格式"><a href="#长格式转宽格式" class="headerlink" title="长格式转宽格式"></a>长格式转宽格式</h2><p>python输出宽格式的方法与excel数据透视表的逻辑一致，使用的函数为df.pivot_table()。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df = df.pivot_table(</span><br><span class="line">    index = [<span class="string">'id1'</span>,<span class="string">'id2'</span>], <span class="comment">#要保留的索引列变量，</span></span><br><span class="line">    columns = <span class="string">'colname'</span>, <span class="comment">#要转置到列变量的分类列，该列的值会成为新的列名</span></span><br><span class="line">    values = <span class="string">'value'</span>, <span class="comment">#分类列对应的值列，这一列会成为新的多个列的对应值</span></span><br><span class="line">    fill_value = <span class="literal">None</span>, <span class="comment"># 缺失值的填充值</span></span><br><span class="line">    margins = <span class="literal">False</span>, <span class="comment">#是否加入小计和项</span></span><br><span class="line">    dropna = <span class="literal">True</span>, <span class="comment"># drop掉所有分类列都没有对应值的item,最好是调整成False以防无法手动检测到缺失值</span></span><br><span class="line">    aggfunc = np.mean, <span class="comment"># 透视的值，主要是在id1,id2对应的columns存在重复项时，需要做一个计算以保证id1,id2的某个分类列只能对应一个值——体现了索引列的意义</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p>需要注意的是pivot_table()对memory要求较高，因此在数据量较大时，最好把关键列以外的变量都踢出，在透视完成后再把踢出的信息通过id1,id2 merge回来。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在数据分析工作中，一个比较麻烦的问题便是从其他人习惯的“excel”表式的wide数据（宽数据）到适合计算机处理、分析、绘图的long格式数据（长数据）的转换。而输出时，一些项目也会对输出的格式提出要求，这就要求我们把长格式输出为宽格式。好在Pandas提供了简洁的数据长宽
      
    
    </summary>
    
    
      <category term="编程与技术" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Python" scheme="https://v-swye.github.io/kanaeba/tags/Python/"/>
    
      <category term="数据清洗" scheme="https://v-swye.github.io/kanaeba/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记：时间的秩序</title>
    <link href="https://v-swye.github.io/kanaeba/2019/11/30/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%97%B6%E9%97%B4%E7%9A%84%E7%A7%A9%E5%BA%8F/"/>
    <id>https://v-swye.github.io/kanaeba/2019/11/30/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%97%B6%E9%97%B4%E7%9A%84%E7%A7%A9%E5%BA%8F/</id>
    <published>2019-11-30T06:32:39.000Z</published>
    <updated>2019-12-01T07:48:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>当时间这一文学上令人无限着迷的概念被纯粹的物理与科学瓦解，又再经如诗歌搬的笔墨重塑，我们才意识到，我们的视角反映出时间的“流动”，而这流动又给予了我们苦痛与永恒的感受。作为一名离物理学已经远去许多年的“曾经理科生”，即使对这本极简科学系列的小册子逐字逐句探究，也会意识到难以把控作者深意和时间的真理。这篇笔记或许是目前为止我敲得最为惶恐的一篇，但无知不应成为追求真理的绊脚石——毕竟，这一切不过是我这小小系统的某种特殊视角罢了。</p><h2 id="时间正在失去它的“性质”"><a href="#时间正在失去它的“性质”" class="headerlink" title="时间正在失去它的“性质”"></a>时间正在失去它的“性质”</h2><p>对时间的直觉是什么呢？它是统一的，我们活在同一个时刻；它具有方向，从过去指向未来；在过去和未来之间，存在名为“当下”的一个瞬间，让我们用“现在”去描述；时间是真实存在的独立维度，即使所有物质都凭空消失，时间也依然以它自己的步伐流动；时间是连续的，我们可以用时间段来描述持续的事件或是运动。然而，当量子力学为我们揭开时间的神秘面纱，时间的上述性质竟一层层消失了——</p><h3 id="统一性"><a href="#统一性" class="headerlink" title="统一性"></a>统一性</h3><p>相对论的结论之一便是，时间在不同地方流逝的速度是不均匀的。爱因斯坦猜想，太阳和地球并未直接吸引，而是对它们之间的事物——空间和时间——产生作用。物体使它周围的时间变慢，举例来讲，时间的流逝在山上就比在海平面上要快，而这种对时间结构的改造进一步影响了物体的运动，使其落向时间流逝速度更慢的地方。<br>时间非均匀的流逝速度意味着统一、绝对时间不复存在。事物演化被分为两个部分，一是该事物相对自己的时间（local time）如何演化，二是这一局部时间相对于其他局部时间如何演化。清楚时间的这一性质的一瞬间，时间就失去了它的统一性。</p><h3 id="方向性"><a href="#方向性" class="headerlink" title="方向性"></a>方向性</h3><p>几乎所有的物理方程都没有过去和未来的明确区分，这些方程指示的运动过程都有其逆过程，唯一一条例外的定律由鲁道夫·克劳修斯提出：不可能把热量从低温物体传到高温物体而不引起任何变化。仅仅在有热量的地方，时间之矢才会出现。</p><blockquote><p>时间与热量的联系是根本性的：每当过去与未来的差别显现，都会有热量参与其中。如果一个过程倒过来看很荒谬，那么一定有东西被加热了。</p></blockquote><p>克劳修斯利用“熵”（S）来度量热量的单向不可逆过程。热力学第一定律确保了能量守恒，而第二定律：$\Delta S &gt;= 0$则暗示，热量只能从高温物体传到低温物体。在语义直觉里，我们把特殊化的低熵定义为过去，而未来总是倾向于非特定无序化下的高熵系统。而这种现象与人类思维活动之间的相互作用，产生了“时间流动”的概念与感觉。<br>然而，这种对过去和未来的区分只是源于我们对世界的模糊和近似。正如一副纸牌，当我们不知道所有的排列可能时，我们认为此前认知到的排列是特殊的；如果我们从所有排列这一全局视角来看，每种排列不过是相同概率下的普通现象。如果我们可以认知到所有排列情况，过去和未来的方向性或许就不再存在了。玻尔兹曼指出，熵是我们模糊视野无法区分的不同排列的数量。过去的低熵源于我们以一种近似、模糊、统计性的方式描述自然。时间流逝的感觉，源于我们无法认知世界的全部细节。</p><h3 id="当下性"><a href="#当下性" class="headerlink" title="当下性"></a>当下性</h3><p>在过去和未来之间，是否有一瞬间，我们处于“当下”？我们已经知道，并不存在一个单一量的绝对时间。即使是最近似的“当下”也只涉及非常邻近的事物，而不会延伸到整个宇宙。如果用纳秒作为时间的精度，“现在”的定义只在几米内；用毫秒，则有数千公里。这便是人类可以做出的最大限度的近似。</p><blockquote><p>客观且统一的当下是不存在的。我们最多也就能说：有一个相对于运动的观察者的当下。那么，对我而言的真实就不同于对你而言的真实。</p></blockquote><p>作者用辈分的概念举例，说明“同辈”和“现在”的概念一样不可靠。当一个家族的代际出现较为复杂的近亲婚姻时，“同辈”的概念就不再是唯一的了，询问谁和谁同辈也就丧失了意义。子女和父母之间建立起次序，但却无法在其他的任意两个人直接构建次序。在数学上，这种现象被定义为偏序：偏序在特定元素之间建立先后关系，而不是在任意两个元素之间。相似地，在狭义相对论之下，时间先后次序是由圆锥组成的偏序，这种次序是局部而非属于宇宙全体的；圆锥本身代表着事物相对固有时的演化，而圆锥之间也存在着相对作用。由此，便形成了一种延展的现在——一系列既非过去亦非未来的事件。<br>这种时间次序的圆锥结构创造了黑洞——黑洞巨大的质量将时间减缓到几乎静止，“现在”这一刻出现在黑洞的边缘（称为视界），边缘将过去和未来相隔离，未来朝向黑洞中。因此，要逃离黑洞，必须向着过去的方向运动，然而这是不可能的，因为物体只能朝向未来运动。</p><h3 id="独立性"><a href="#独立性" class="headerlink" title="独立性"></a>独立性</h3><p>最开始，两位伟大的科学家对时间和空间提出了两种截然不同的解释。亚里士多德认为，时间是物体的空间秩序，没有物体以及其延展接触，就没有空间和时间的存在；而牛顿认为，物体之间还存在着有别于世界上其他物质的“空的空间”。科学的发展揭示出二者中央存在的事实真理，即时间与空间是真实的<strong>相对</strong>现象，它们真实存在，但绝不独立于发生的事件。<br>“引力场”是引力的来源，也是构成牛顿时空的材料。不过，牛顿所描述的引力场是一种平面，可以用欧式几何的方法进行测量；而实际上，在引力波的作用下，引力场也可以波动起伏，通过收缩和膨胀产生弯曲的时空，一个地方的时空被拉长，与另一个地方的更短的时空对应。<br>时间的非独立性可以从电子实体化出发理解。电磁场和引力场一样，是构成世界物理实在的物质。当电子被发射出时，它具体会落在哪一点上并不为人知晓，只是依照一定的概率分布；当它最终与其他相互作用的物体发生关联时，电子才会实体化，例如与屏幕碰撞。引力场也是这样，当发生相互作用时，只有对与之相互作用的物体来说，时间才是分立确定的；对于宇宙的其他部分，它们仍然是不确定的。</p><h3 id="连续性"><a href="#连续性" class="headerlink" title="连续性"></a>连续性</h3><p>很难想象，时间竟然具有一个最小的单位，在这个单位上，时间是离散的。量子力学的名字即来源于此：量子就是基本微粒。最小的时间被称为“普朗克时间”，多种描述相对论、引力和量子力学的变量和常数决定了这个时间为$10^{-44}$秒。</p><h2 id="世界是事件的网络"><a href="#世界是事件的网络" class="headerlink" title="世界是事件的网络"></a>世界是事件的网络</h2><p>时间失去的那些性质并不会改变一个事实：没有物体存在，只有事件在发生，世界是事件的网络。一块石头也不是一块石头，而是一段持续的维持这一形态的事件，而它也终究走向损毁和重铸。人也不是物体，而是社会关系、化学过程和情感交流网络中的一个结点。</p><h3 id="热学时间与世界熵"><a href="#热学时间与世界熵" class="headerlink" title="热学时间与世界熵"></a>热学时间与世界熵</h3><p>热学时间的决定遵循以下流程：宏观态——模糊——时间。一个宏观态在模糊中选择了一些具有时间特征的特殊变量，而模糊本身决定了时间。这些特殊变量的确定并非独立行为，而是相互作用的结果，其相互作用的顺序则形成了时间顺序的最初形式。例如，先测量电子的位置、再测量其速度，其状态改变就与先测速度、再测量其位置有所不同，这被称为量子变量的“非对易”。顺序的交换影响着我们对状态的认知，非对易确定了两个物理量的顺序的同时也就带来了时间的起源。即便测量了所有的可测变量，世界的不可预知性也仍然存在。<br>我们与世界的相互作用也是如此。为什么世界的不同状态对我们来说几乎没有不同？这是因为我们所处的这部分世界与其他部分的相互作用会忽视很多变量，而这就造成了我们对世界的模糊视野。正如前文所述，熵衡量了我们无法识别的微观状态的数量，A系统相对于B系统的熵，是A和B在相互作用过程中无法被区分的A的状态的数量。世界相对于我们的熵也是如此，不仅取决于世界本身状态数量，也取决于我们选择与哪些变量相互作用、取决于我们模糊世界的方式。</p><h3 id="视角与时间流动的体验"><a href="#视角与时间流动的体验" class="headerlink" title="视角与时间流动的体验"></a>视角与时间流动的体验</h3><p>有别于从外部观察的世界时间结构——无时间顺序排列的事件集合，我们对时间的经验源于我们身处世界之中的观察。在这个巨大的宇宙中，存在一些特殊的低熵状态的小系统，这些系统的熵是增加的，而这种增加就是我们体验到的时间流动。因此，特殊的并不是宇宙的状态，而是我们所属的小系统。</p><h3 id="世界运转的源头"><a href="#世界运转的源头" class="headerlink" title="世界运转的源头"></a>世界运转的源头</h3><p>根据热力学第一定律，能量始终是守恒的。因此，世界运转需要的并非能量，而是低熵，以及低熵存在带来的熵增过程。地球的低熵源就是太阳——太阳发送热光子，而地球发送冷光子，冷热光子相遇互相交换能量，为了确保恒温，输入和输出的能量是大致相等的，而1个热光子可能与10个冷光子的热量对应，但其可能存在的状态数量却远少于10个冷光子可以构造的状态数量。因此，太阳作为低熵源，为地球提供了运作和发展的主要动力。而太阳本身则来自熵更低的状态，一直追溯、递归到宇宙最初的极低熵。<br>熵增过程如何让我们认知到，低熵的才是过去，未来则走向更高的熵呢？作者认为，过去会在现在留下痕迹，而这就是因为过去的熵更低；通过痕迹，我们才能区分过去和未来。不过，在基本层次上，物理法则不讨论原因，只讨论规律，而这些规律在过去和未来中是对称的。</p><h2 id="时间秩序的哲学"><a href="#时间秩序的哲学" class="headerlink" title="时间秩序的哲学"></a>时间秩序的哲学</h2><h3 id="身份的三要素"><a href="#身份的三要素" class="headerlink" title="身份的三要素"></a>身份的三要素</h3><p>在《基因传》里，作者从基因的角度讨论了如何从文化、社会与政治角度来定义、分类和理解人类自身的身份。而这里，作者则从时间和物理相互作用的角度探讨了身份认知的三大重要要素，即视角、反映和记忆。<br>第一，世界上每个人都有自己的视角，通过自身与世界的相互关联，世界在每个人那里得到属于这个人的独特映现。<br>第二，我们的生活是社会性的，关于自我的概念并不源于自省，而是源于我们与其他人、与周围环境的相互作用。我们从同类得到反馈，形成自我的观念，我们自身便是这些观念的映象。<br>最重要的一个要素便是记忆。过去的低熵留下了痕迹，或许记忆也是这样。记忆把分散在时间中的过程联结在一起，而这些过程组成了我们。记忆的存在使我们得以测量时间——当下存在于我们头脑中的东西。</p><blockquote><p>奥古斯丁意识到，对时间流逝的感知是内在的，它是头脑不可或缺的一部分，是过去在大脑中留下的痕迹。</p><p>现在，在我们的记忆里，在我们的期待里。我们渴望永恒，我们忍受着时间的流逝，我们因时间而受苦。我们的存在应该归功于它，它给予了我们存在这个珍贵的礼物，让我们可以创造转瞬即逝的幻觉——永恒——我们所有痛苦的根源。</p><p>然后乐声逐渐消失。“银链折断，金罐破裂，瓶子在泉旁损坏，水轮在井口破烂；尘土仍归于地。”这样很好。我们可以闭上双目，开始休息了。对我来说，这一切合理又美妙。这就是时间。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;当时间这一文学上令人无限着迷的概念被纯粹的物理与科学瓦解，又再经如诗歌搬的笔墨重塑，我们才意识到，我们的视角反映出时间的“流动”，而这流动又给予了我们苦痛与永恒的感受。作为一名离物理学已经远去许多年的“曾经理科生”，即使对这本极简科学系列的小册子逐字逐句探究，也会意识到难以
      
    
    </summary>
    
    
      <category term="读万卷书" scheme="https://v-swye.github.io/kanaeba/categories/%E8%AF%BB%E4%B8%87%E5%8D%B7%E4%B9%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>读书笔记：蜜蜂与远雷</title>
    <link href="https://v-swye.github.io/kanaeba/2019/11/19/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E8%9C%9C%E8%9C%82%E4%B8%8E%E8%BF%9C%E9%9B%B7/"/>
    <id>https://v-swye.github.io/kanaeba/2019/11/19/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E8%9C%9C%E8%9C%82%E4%B8%8E%E8%BF%9C%E9%9B%B7/</id>
    <published>2019-11-19T14:37:04.000Z</published>
    <updated>2019-11-23T07:48:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>这是一本我读完了也没有意识到标题是《蜜蜂与远雷》而非《蜂蜜与远雷》的书。虽说一直以来对日本文化都有十足的兴趣，甚至自学拿到了日语N1，但我对日系得奖作品一般还是敬而远之的。年少时还是爱轰轰烈烈的故事，爱意味深长又入门三分的讽刺，爱波澜壮阔的叙事诗。日系中也不乏这样的文学作品，但体现多数日本民众口味的获奖作品则往往过于平淡——不是说平淡的文学不好，只是太日常的时候，总觉得无法更好地体验想象与现实间明确的分割线。吸引我的完全只是这本书的主题：钢琴，古典音乐，音乐家的逐梦故事。孩童时期与音乐相伴的幸福与缺憾，至今仍偶尔如毒蛇般现身、在心尖萦绕。从《四谎》、《琴之森》到《蜜蜂与远雷》，我都在为这条毒蛇都贪婪地试图从虚构作品中汲取营养，寻求片刻安宁。毕竟，</p><blockquote><p>这个世界，每时每刻都被美妙绝伦的音乐充满。</p></blockquote><h2 id="音乐追求的是瞬间"><a href="#音乐追求的是瞬间" class="headerlink" title="音乐追求的是瞬间"></a>音乐追求的是瞬间</h2><p>记得在读《熊镇》的时候，有一句这样形容体育的话：“体育能给我们的只有片刻。但是，人生除了片刻还剩下什么？”也许在恩田陆眼里，在对片刻的追求上，音乐与体育并无区别。拼尽一生成为“会弹”的专业音乐家，最终都是为了追求“那个瞬间”，一旦品尝了瞬间的快乐，便无法再度从这样的诱惑身边逃离。在风间尘思考如何在决赛中展现自己的音乐时，他与插花老师之间的交流也暗示着一切艺术追求的统一性：“美丽的一瞬间就意味着永远。在创造出至上的一瞬，插花的我也存活在那至上的一瞬间。那一瞬间就是永远，可以是永远地存在下去了。”<br>这种对美的极致追求颇有些日式的极端意味，但抛开文化偏向不谈，人类对艺术、对美感存在的瞬间的追求依然是共通的。一瞬间即是永远，再现的时候，这永远的一瞬便又会活过来。</p><h2 id="音乐属于所有人"><a href="#音乐属于所有人" class="headerlink" title="音乐属于所有人"></a>音乐属于所有人</h2><p>音乐之神的馈赠不仅将一度消沉引退的亚夜重新带到舞台的聚光灯下、为明石这样在重复而枯燥的生活中即将平淡度过一生的平凡人再度点燃希冀的光芒，更是滋润了在座的、和所有愿意用耳朵倾听的人。音乐不仅仅是天才少年少女的尊享特权，而是漫长的时间长河中人类内心深处的呼唤与大自然的回响。</p><h2 id="把音乐带出去"><a href="#把音乐带出去" class="headerlink" title="把音乐带出去"></a>把音乐带出去</h2><p>风间尘的老师霍夫曼一直强调，希望风间尘可以延续他的努力，把音乐带出去。在整个芳江国际钢琴大赛的过程中，风间尘甚至评审们都在思考：他是怎样的礼物？又要怎样将音乐带出去？一开始，评审三枝子的想法是自然产生的：老师希望风间尘可以打破老旧的评审规则，像一份炸弹一样考验这个世界对音乐的评判。然而，他们最后发现，所谓带出去，并不是要从风间尘身上直接得到什么旋律，而是希望借由他对音乐自由、浪漫的表达精神，通过声音传达给在场的观众、钢琴家和专业评审，激发他们对音乐的想象和再审视，特别是钢琴家本身对音乐的理解。</p><p>与其他最终需要接地气、沦为“消费品”的艺术一样，音乐家有时不得不向大众屈服。在市场上，把音乐当成工作的音乐家需要提供的是由大众需求引导的商品，而在大赛中，又面临将传递、理解作曲家本人的背景和思想放在首位的评审准则。这种在市场需求与个人表达间的两难境地不由得让我想起了以前在Medium上读的一篇关于星巴克为何无法在澳洲获得成功的文章——其中一个理由就是，星巴克视咖啡为product，而在澳洲当地咖啡更多地被视为一种experience，是人与人之间产生联系的纽带。而音乐，又是否能获得与澳洲咖啡一样的看待方式呢？作者认为，把音乐带出来，就是将沉眠在钢琴家心底的表达呼唤出来，带向世界——在这个现代音乐强调市场需求，对古典音乐施加许多桎梏，无法产生“新古典音乐”的时代。</p><h2 id="隐含的情感线"><a href="#隐含的情感线" class="headerlink" title="隐含的情感线"></a>隐含的情感线</h2><p>这是一本关于音乐的书。即使如此，作者依然在乐谱中以几乎不可察觉的笔墨描绘了各个角色之间的感情牵连，而这些情感的谱线依然带有浓浓的日式风味——除了外国人马赛尔和生于法国的风间尘，所有的日本角色对于感情二字，都有几分“绝望”的影子。亡故的母亲如影随形地追随亚夜，亚夜对风间尘一种可以视作“救世主”的错觉，雅美望向明石时眼中的微妙情绪，三枝子和不入籍的公务员“婚姻”以及即使知道过去两人吵架到不可开交也在几句“你什么时候回我身边”之后便准备重新与（刚离婚的）前夫再续前缘——只因她知道，她的音乐需要他懂。</p><p>只是我觉得，若是追寻纯粹的音乐，加这些“物哀”式的感情，实在有些多余；而若是要描绘感情，则过于吝啬笔墨，无法直抵人心。</p><h2 id="日式一针见血"><a href="#日式一针见血" class="headerlink" title="日式一针见血"></a>日式一针见血</h2><p>一场钢琴比赛也是一场人性的较量，在音乐之神的注视下，无人可以躲过剖开自身的要求。在作者的笔墨下，不少情节一针见血地指出了人类都难逃的有趣本性，例如：</p><blockquote><p>一般，演奏难度高的曲子时，参赛者会摆出“接下来要弹一首很难的曲子”的架势，连职业钢琴家也难以免俗。这样一来，似乎曲子的难度又被提高了，听众也更觉得“这是一首很难的曲子”。</p></blockquote><p>这种“暗示”的心理效应在任何涉及“arts”的场合都不可免俗，说难听点就是“装逼”。为了推销某样东西，我们的确不可避免地需要为产品设计包装、美化宣传，而这竟也是expected的。</p><blockquote><p>真是的，这群天才。她自己感到了一丝被排除在外的感觉。在这个才能竞现的世界上，她经常感到这种距离感。这些孩子，根本不知道自己有多么幸运。有无数想成为音乐家的人，为自己是否真正有音乐才能而苦恼，每天花很长的时间练习，但是仍然会频频出错，担心自己弹不好，担心到胃疼，睡不着觉，被自己的平凡打败，仍然离不开音乐，这些人的心情，他们能理解吗？不，他们不可能不知道。要比辛苦，每个人的辛苦都不同，无法比较。她一直待在亚夜身边，所以看得明白。被唤作天才的人，也有他们的烦恼和辛苦。天才少女的陨落，亚夜并不是不知道这意味着什么。虽说她心胸宽阔，但也受到了打击。当时突然消失于舞台上，引起的骚动，到现在都难以忘怀。今后的人生不知道会是怎样。就算是好像已经走上明星的光明大道的马赛尔，未来也不是百分之百有保证。以前也曾有无数的神童被命运戏弄。看起来幸运万分，最后却以悲惨的结局收尾。在这个世界上，在他们前面，已经堆积了累累尸骸。<br>天才只会被与自己平等的人影响。有些东西，只有天才之间才会懂得。</p></blockquote><p>必须正视天才与凡人之间的差异，如果做不到这一点，天才会走向盲目，凡人则会因嫉妒而发疯。然而，他们又是一样的，一样需要通过努力将已有的才华最大限度地释放出来，一样要忧虑自己是否会被命运戏弄，在无情的竞争中失去立足之地，被时间的洪流冲到不知何处去。</p><h2 id="关于书本身"><a href="#关于书本身" class="headerlink" title="关于书本身"></a>关于书本身</h2><h3 id="滚滚远雷的蜂蜜"><a href="#滚滚远雷的蜂蜜" class="headerlink" title="滚滚远雷的蜂蜜"></a>滚滚远雷的蜂蜜</h3><h4 id="音乐不等于自然"><a href="#音乐不等于自然" class="headerlink" title="音乐不等于自然"></a>音乐不等于自然</h4><p>恩田陆对于诠释每一首曲子作出的努力值得赞许，然而几乎所有曲子的描绘手法都是千篇一律的自然风光。不可否认，上古人类哼出第一段曲调时，他们想表达的很有可能是内心深处对自然的一种体验和敬意；然而，随着人类物种的进化和社会的发展，音乐中包含的感情绝非“自然”就可以全部诠释，不同的音乐家在她人生的不同时刻弹奏同一首曲子，都不会有完全一样的旋律。在这一点上，本书作者是否有些囿于日本传统意义上对于自然的敬意和热爱，而忽视了音乐中那种或强烈或隐喻的情感联系呢？</p><h4 id="音乐是否属于所有人"><a href="#音乐是否属于所有人" class="headerlink" title="音乐是否属于所有人"></a>音乐是否属于所有人</h4><p>从一开始，恩田陆想要表达的，就是音乐是属于所有人的；不是只有天才少年少女才可以与音乐共舞，任何一个追求美、追求表达美的人都可以享受音乐带来的震撼和“瞬间之美”。这种观念直接体现在明石这个角色上，而他作为年龄最大的参赛者之一，也的确带来了不同韵味的、充满人生哲理的音乐。然而可惜的是，除了数笔描绘后就匆匆逝去的明石故事，整本小说的主线依然是围绕天才少年少女展开，强调他们的才华是如何横溢、对音乐的感知是如何传神<br>。的确，在竞争激烈的音乐比赛中，获胜需要的是绝对的才华；可这终究还是缺乏背后付出的印象，而那些似乎对音乐家的音乐做出极大贡献的“重大变故”实在是略微牵强。</p><h3 id="一本有声的书"><a href="#一本有声的书" class="headerlink" title="一本有声的书"></a>一本有声的书</h3><p>当对音乐的自然通感出现一次时，是惊艳；两次，是沉醉；三次，是享受。然而，当这样的通感出现了无数次，再精致的描写也显得无力笨拙。讽刺的是，文中还这样批评过拉赫玛尼诺夫的《第三协奏曲》：</p><blockquote><p>“一首到处都是亮点，无论取出哪一段都很棒，会成为演奏中的最大看点的华丽协奏曲”，“所以听《第三协奏曲》，会有一些冗长无趣的感觉。亮点就像短片一样一个接一个，弹来弹去都是高潮”。</p></blockquote><p>在这五百多页的冗杂中，我的建议只是，读可以读，但不必抱着一鼓作气的心态，否则只会像突然跑了一次全程马拉松，到最后一直在被跑步折磨，无法享受跑步本身带来的快乐。更好的选择是偶然一个清闲的下午，翻开一章打开播放器，听着久远历史里人类声音的精华品味。</p><blockquote><p>Music，这个词的语源，是“神的技艺”，是缪斯的丰收。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这是一本我读完了也没有意识到标题是《蜜蜂与远雷》而非《蜂蜜与远雷》的书。虽说一直以来对日本文化都有十足的兴趣，甚至自学拿到了日语N1，但我对日系得奖作品一般还是敬而远之的。年少时还是爱轰轰烈烈的故事，爱意味深长又入门三分的讽刺，爱波澜壮阔的叙事诗。日系中也不乏这样的文学作品
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>使用python实现条件在险价值（CVaR/ES）计算</title>
    <link href="https://v-swye.github.io/kanaeba/2019/11/13/%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E6%9D%A1%E4%BB%B6%E5%9C%A8%E9%99%A9%E4%BB%B7%E5%80%BC%EF%BC%88CVaR-ES%EF%BC%89%E8%AE%A1%E7%AE%97/"/>
    <id>https://v-swye.github.io/kanaeba/2019/11/13/%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E6%9D%A1%E4%BB%B6%E5%9C%A8%E9%99%A9%E4%BB%B7%E5%80%BC%EF%BC%88CVaR-ES%EF%BC%89%E8%AE%A1%E7%AE%97/</id>
    <published>2019-11-13T10:59:37.000Z</published>
    <updated>2019-11-14T10:59:09.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="定义与计算原理"><a href="#定义与计算原理" class="headerlink" title="定义与计算原理"></a>定义与计算原理</h2><p>条件在险价值（CVaR）又名期望损失（Expected Shortfall）。如果说在险价值（VaR）是统计上某个分位点值的话，ES就是这个分位点以下损失的期望。因此，基于样本数据计算$\alpha$分位处的条件在险价值的基本步骤如下：</p><ol><li>计算指定频率的收益率（假设有N个样本点）</li><li>将收益率按从低到高排列</li><li>寻找位于分位点的样本点（第$N*\alpha$个样本，注意这个样本对应的收益率，或者说损失，就是传统的VaR）</li><li>计算低于该样本点的所有损失的均值$\frac{\sum^{m}_{i}X_i }{m}$。</li></ol><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map_CVaR</span><span class="params">(series, alpha)</span>:</span></span><br><span class="line"> <span class="string">"""</span></span><br><span class="line"><span class="string"> - Series: 一个产品的一系列收益率数据</span></span><br><span class="line"><span class="string"> - 使用方法：设有某个每一列为一个产品数据的dataframe df: df.apply(map_CVaR, alpha = 0.01)</span></span><br><span class="line"><span class="string"> - 返回值：该产品样本对应的CVaR值</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line">    series = series.sort_values(ascending = <span class="literal">True</span>)</span><br><span class="line">    df = pd.DataFrame(series) </span><br><span class="line">    N = len(df)</span><br><span class="line">    m = int(N*alpha)</span><br><span class="line">    df[<span class="string">'count'</span>] = np.arange(<span class="number">1</span>,N+<span class="number">1</span>)</span><br><span class="line">    df = df[df[<span class="string">'count'</span>] &lt;= m]</span><br><span class="line">    <span class="keyword">return</span> -df.iloc[:,<span class="number">0</span>].mean()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;定义与计算原理&quot;&gt;&lt;a href=&quot;#定义与计算原理&quot; class=&quot;headerlink&quot; title=&quot;定义与计算原理&quot;&gt;&lt;/a&gt;定义与计算原理&lt;/h2&gt;&lt;p&gt;条件在险价值（CVaR）又名期望损失（Expected Shortfall）。如果说在险价值（VaR
      
    
    </summary>
    
    
      <category term="编程与技术" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Python" scheme="https://v-swye.github.io/kanaeba/tags/Python/"/>
    
      <category term="金融" scheme="https://v-swye.github.io/kanaeba/tags/%E9%87%91%E8%9E%8D/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记：学会提问</title>
    <link href="https://v-swye.github.io/kanaeba/2019/11/09/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%AD%A6%E4%BC%9A%E6%8F%90%E9%97%AE/"/>
    <id>https://v-swye.github.io/kanaeba/2019/11/09/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%AD%A6%E4%BC%9A%E6%8F%90%E9%97%AE/</id>
    <published>2019-11-09T03:15:31.000Z</published>
    <updated>2019-11-17T07:37:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>在当下这个信息爆炸的时代，唯有拥有批判性思考的能力，才能在扑面而来的信息潮流中捕获些许真正能支撑自己成长的力量。一直以来，我都以相对具有从多方面客观看待事物的能力而感到自豪，直到遇到这本书我才知道——尽管我已经成功避免了某些常见的思维偏误，但我还做得远远不够，无论是接受信息还是通过写作等方式传达信息。我相信，每个人在任何一个年纪遇到这本书，都将有所裨益（成为一名合格的杠精）。</p><h2 id="批判性思考"><a href="#批判性思考" class="headerlink" title="批判性思考"></a>批判性思考</h2><blockquote><p>我们倾听他们，是为了构建出自己的答案。</p></blockquote><h3 id="为什么要批判性思考"><a href="#为什么要批判性思考" class="headerlink" title="为什么要批判性思考"></a>为什么要批判性思考</h3><p>正如《乌合之众》中勒庞对群体的讽刺——领导群体需要的不是真理，而是“断言”——似乎人性中天生就有一种偷懒的倾向，尽可能避免麻烦的推导、寄希望于他人可以直接告诉我们结果。然而从历史上来看，一旦对之加以利用形成偏向性的煽动，其结果对整个人类社会来说都是灾难性的。批判性思维的起点，就在于个体要有提高思维能力的强烈愿望，选择自己的主见，而非一味全盘接受。</p><h3 id="什么是批判性思维"><a href="#什么是批判性思维" class="headerlink" title="什么是批判性思维"></a>什么是批判性思维</h3><p>作者认为，批判性思维包括以下三点：</p><ol><li>要能意识到它们是一整套环环相扣的关键问题；</li><li>有能力在适当时机以适当的方式提出和回答问题；</li><li>积极主动地使用这些关键问题的强烈渴望。</li></ol><p>当作者或演讲者等观点的陈述人不断向你兜售观点时，应该随时准备与之辩驳，这种互动方式被称为“淘金式思维”。</p><h4 id="海绵式与淘金式思维"><a href="#海绵式与淘金式思维" class="headerlink" title="海绵式与淘金式思维"></a>海绵式与淘金式思维</h4><p>或许是由于中国传统的教育方式仍强调灌输为主，我们大部分人都在无意中形成了海绵式思维——即大量吸收外部信息。但这种思维在选择接受或摒弃哪些信息和观点上毫无帮助。淘金式思维（panning-for-gold style of thinking）则强调观点的接收方和传输方间多加互动，不断提问并思考问题的答案。</p><h4 id="强势与弱势批判性思维"><a href="#强势与弱势批判性思维" class="headerlink" title="强势与弱势批判性思维"></a>强势与弱势批判性思维</h4><p>拥有批判性思维并不意味着形成理性的主见。一般来讲，我们都有一种“弱势批判性思维”的倾向，即利用批判性思维来捍卫自己的理念，以驳倒与自己不同的观点和论证为终极目标。然而，这种对自己主张的绝对信任无益于追求真理。强势批判性思维要求我们对包括自己在内的所有主张提出批判性的问题，以评估所有的断言以及信念。</p><h4 id="快思考与慢思考"><a href="#快思考与慢思考" class="headerlink" title="快思考与慢思考"></a>快思考与慢思考</h4><p>在使用弱势批判性思维时，我们就已经落入了名为“快思考”的陷阱。本书的作者在更新这一版内容时，特意将原书内容与《思考，快与慢》结合，挖掘快思考和慢思考这两个抽象概念中的实际表现。快思考可谓人类懒惰本性下的常见倾向，一旦事实的确符合快思考得出的结论，就可以节省下大量的时间，但这种倾向同时会导致我们无法对一个问题进行深入细致的分析。常见的快思考倾向包括：</p><ul><li>只愿意听价值观倾向和我们相似的人的话</li><li><strong>刻板印象</strong>：基于某个人所属的特定群体断言此人具有的一系列明确特征，绕开客观评价的艰难过程</li><li><strong>晕轮效应（halo effect）</strong>：先认识到一个人身上具有的优缺点，然后把这些特征与这个人的其他一切都联系起来。如果对一个人有着积极的认识，便以为他在其他方面也有着过人之处，便特别容易接受他的观点</li><li><strong>确认性偏见（confirmation bias）</strong>：只把那些确认我们既有信念的证据当成可靠证据，并最终导致<strong>信念固着（belief perseverance）</strong></li><li><strong>可得性启发（availability heuristic）</strong>：只根据手边最容易获得的信息来形成结论，而不付出时间和精力获取、处理额外的信息</li><li><strong>近因效应（recent effect）</strong>：最新看到的信息占有影响评判标准的最高权重；例如，尽管空难的概率非常低，但出现一场空难后有些乘客几个月也不敢乘飞机出行</li><li><strong>似是而非（truthiness）</strong>：相信希望是真的概念或事实而非已经证明为真的概念或事实</li><li><strong>奇迹式思维（magical thinking）</strong>：在科学还不能提供令人信服的解释时，人们寻求奇迹来解释，“将特定的结论变成现实”。</li></ul><p>这些快思考方式不仅影响一个人对严肃讨论和议题的评估能力，同时也在日常生活和社交中扮演着重要角色；无论何时，我们都应该多加询问一下自己：是否陷入了快思考的陷阱中？</p><h2 id="评价论证"><a href="#评价论证" class="headerlink" title="评价论证"></a>评价论证</h2><h3 id="论题"><a href="#论题" class="headerlink" title="论题"></a>论题</h3><p>要评估一个论证，首先需要知道这个论证提出了什么样的问题，也即论题。论题一般可以分为描述性论题和规定性论题。</p><ul><li>描述性论题：针对各种客观描述的精确与否提出的问题，即<strong>“是不是”</strong></li><li>规定性论题：伦理或道德范畴，需要的是关于<strong>“应该”怎么样</strong>的规定性答案。社会争论通常属于规定性论题，其关注的焦点在于好坏对错，而非对既有事实的认知和描述。</li></ul><h4 id="术语界定"><a href="#术语界定" class="headerlink" title="术语界定"></a>术语界定</h4><p>在提出论题的时候，首先要避免的是模糊的定义。与“一千个读者心中有一千个哈姆雷特”的不同，歧义的产生只会导致整个论证都无法精准地传达给受众，而且这种误解的频率远远高于我们的想象——很多我们以为的常识实际并不广为人所知，或者至少还欠缺着一个被广泛接受的统一的定义。例如，“人权”这个词如果出现在挪威政府，那可能就是指就业权、免费医疗权、房屋住宿权，而美国参议员所说的“人权”则可能指言论自由、宗教信仰等权利。因此，应当小心使用每一个沾有专业性的词汇，最好的做法是以其他人从未听过这个词语为前提，而不是默认受众早已得知关键词的含义。同时，鼓励听众提出问题，从而确保自己所想要表达的意思和实际表达的意思一致。<br>常见的界定术语的方法有以下三种：同义替换（synonyms）、举例说明（examples）和具体标准定义（definition by specific criteria）。然而，前两种都具有很高的误导性，只适用于一种定义的具象化补充，对于客观评价大多数有争议的论题并不合适。更有甚者将大量“附加感情色彩的术语”（loaded terms）用于激发强烈的情感反应，以此达到个人目的。例如，政治语言通常都带有强烈的感情色彩，并且尽可能地模棱两可。</p><h3 id="论证"><a href="#论证" class="headerlink" title="论证"></a>论证</h3><h4 id="论证结构"><a href="#论证结构" class="headerlink" title="论证结构"></a>论证结构</h4><p>一个论证由一个结论以及支撑这一结论的各种理由组成，而把这些散乱的节点联系在一起的正是“假设”。</p><h4 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h4><p>假设是一种被作者认为理所当然并用来证明外在论证的信念，由于假设一般不会明说出来，这一环节就成为了对一个论证理解和把握的关键点。只有读者和作者之间对这些“理所当然”的信念达成一致时，这一论证才是对于双方都成立的。假设一般存在于两个地方：</p><ul><li>连接性假设（linkage assumption）：理由需要它们才可以证明结论</li><li>证明性假设：理由需要它们才能成立</li></ul><p>而假设又根据其内涵意义可以分为价值观假设（value assumption）和描述性假设（descriptive assumption）。描述性假设指的是对世界是什么样的一种信念。而所谓价值观假设是指一种想当然的想法，认为某些相互对立的价值观中一个比另一个更重要。需要注意的是，在不同的情景和问题背景下，一个人的价值倾向并不一定是相同的。同时，也不能因为一个人是某个团体的一员，就断然假设这个人会无条件支持群体的价值观假设。</p><blockquote><p>要判断一个人的价值观假设，一个重要的方法就是注意他用来证实结论的各种理由，然后判断哪些价值倾向会导致作者认为这些理由比其他理由更可取。</p></blockquote><h2 id="常见误区"><a href="#常见误区" class="headerlink" title="常见误区"></a>常见误区</h2><h3 id="类比"><a href="#类比" class="headerlink" title="类比"></a>类比</h3><p>虽说在做关键术语定义时，具体完整的学术性定义在严谨的逻辑推理中更受推崇，但有时为了更具象化、接地气地传达意思，论证者通常会引入类比的手段；而在一些新的结论出现前，人们也会通过类比来获得一些创新的启发。要评价一个类比的质量，需要关注两个因素：</p><ol><li>A和B之间如何相同和不同；</li><li>相同点和不同点之间的相关性。</li></ol><p>从某种意义上说，所有类比都是错误的，因为它假设两样东西在一两个方面有相似之处，则在其他重要方面也必然存在相似之处。因此，如果一个作者通过和另一件事对比来得出一件事的结论，则进一步证据支撑这种类比是有所必要的。</p><h3 id="因果与相关"><a href="#因果与相关" class="headerlink" title="因果与相关"></a>因果与相关</h3><p>两个变量之间具有相关性可能有以下四种解释：</p><ol><li>A是B的原因；</li><li>B是A的原因；</li><li>A和B相互影响（双向因果，因果混淆谬误）；</li><li>A和B有关系是因为C（忽略常见原因谬误，neglect of common cause fallacy）。<h3 id="谬误"><a href="#谬误" class="headerlink" title="谬误"></a>谬误</h3>书中给出的一些常见的谬误包括：</li><li>因果混淆谬误（confusion of cause and effect fallacy）</li><li>忽略常见原因谬误（neglect of common cause fallacy）</li><li>事后归因谬误（post hoc, ergo propter hoc）：错误认为第一件事情引起第二件事情是因为它发生在前</li><li>基本归因错误（fundamental attribution error）：高估他人行为中个人倾向的重要性而低估了环境因素的作用。</li></ol><h3 id="二分式思维与改进"><a href="#二分式思维与改进" class="headerlink" title="二分式思维与改进"></a>二分式思维与改进</h3><p>二分式思维方法（dichotomous thinking）往往将一个可能存在多种答案的问题假设成只有两个可能的答案，这也是“绝对”化论证的罪魁祸首之一。当然，就像物质最终可以回到原子等基本组成成分，一切论证本身都可以划归到二分式思维，我们需要改进的就是利用这种本质来创造多个条件句，从而得到更加准确的论证和结论。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在当下这个信息爆炸的时代，唯有拥有批判性思考的能力，才能在扑面而来的信息潮流中捕获些许真正能支撑自己成长的力量。一直以来，我都以相对具有从多方面客观看待事物的能力而感到自豪，直到遇到这本书我才知道——尽管我已经成功避免了某些常见的思维偏误，但我还做得远远不够，无论是接受信息
      
    
    </summary>
    
    
      <category term="读万卷书" scheme="https://v-swye.github.io/kanaeba/categories/%E8%AF%BB%E4%B8%87%E5%8D%B7%E4%B9%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>使用python实现超额收益率、波动率、最大回撤、卡玛比率的计算（基于周净值）</title>
    <link href="https://v-swye.github.io/kanaeba/2019/10/24/%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E8%B6%85%E9%A2%9D%E6%94%B6%E7%9B%8A%E7%8E%87%E3%80%81%E6%B3%A2%E5%8A%A8%E7%8E%87%E3%80%81%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%92%A4%E5%8F%8A%E5%8D%A1%E7%8E%9B%E6%AF%94%E7%8E%87%E8%AE%A1%E7%AE%97/"/>
    <id>https://v-swye.github.io/kanaeba/2019/10/24/%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E8%B6%85%E9%A2%9D%E6%94%B6%E7%9B%8A%E7%8E%87%E3%80%81%E6%B3%A2%E5%8A%A8%E7%8E%87%E3%80%81%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%92%A4%E5%8F%8A%E5%8D%A1%E7%8E%9B%E6%AF%94%E7%8E%87%E8%AE%A1%E7%AE%97/</id>
    <published>2019-10-24T10:59:37.000Z</published>
    <updated>2019-10-25T09:26:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>在做私募基金评价时，我们会使用不同的指标来量化该基金产品在各个维度上的表现。常见的四个指标包括超额收益率（衡量收益），波动率、最大回撤（衡量风险），卡玛比率（性价比）。其中卡玛比率类似常见的夏普比率，但具体到私募基金而言，由于私募基金相比公募基金更强调绝对收益，故使用绝对收益为分子的卡玛比率（定义见后文）比以超额收益为收益因子的夏普比率更为合适。进一步地，这四个指标还可以基于给定窗口计算滚动表现。下面，本文将具体介绍基于周净值计算对应指标的公式、意义、思路及具体代码实现。</p><div class="table-container"><table><thead><tr><th>基本指标</th><th>衡量维度</th><th style="text-align:right">扩展指标</th></tr></thead><tbody><tr><td>收益率</td><td>收益</td><td style="text-align:right">超额收益率，绝对收益率，k年滚动超额收益率（年化）</td></tr><tr><td>波动率</td><td>风险</td><td style="text-align:right">近1年波动率（年化），k年滚动波动率（年化）</td></tr><tr><td>最大回撤</td><td>风险</td><td style="text-align:right">近1年最大回撤，k年滚动最大回撤</td></tr><tr><td>卡玛比率</td><td>性价比</td><td style="text-align:right">近1年卡玛比率，k年滚动卡玛比率</td></tr></tbody></table></div><h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><h3 id="超额收益率"><a href="#超额收益率" class="headerlink" title="超额收益率"></a>超额收益率</h3><p>记ER为超额收益率，AR为绝对收益率，BR为基准收益率，则超额收益率的公式为：</p><script type="math/tex; mode=display">ER_i = AR_i - BR_i</script><p>其中i为样本的某个观测点。若以周净值数据作为样本，那么i就是周记录频率下的某一周，$ER_i$即为第i周的超额收益率。基准收益率和绝对收益率的计算可能基于简单收益率，也可能是对数收益率。<br>超额收益率衡量了投资组合/基金产品相对业绩基准的表现，因此所选择的基准将对结果产生关键影响。除了采用产品所公开的业绩比较基准以外，一种基准指数的选择思路是根据基金所使用的策略分为股票（沪深300等）、债券（中证全债）、组合基金和其他（绝对基准）等。</p><h3 id="波动率"><a href="#波动率" class="headerlink" title="波动率"></a>波动率</h3><p>波动率在数学上的来源就是绝对回报的标准差。在某个观测区间内（例如1年），我们可以计算出一系列绝对收益数据，并求取其标准差。但需要注意的是，我们通常会对所得结果进行年化，以求在相同标准下进行比较。假设每个观测点之间的间隔为$d$年，则基于该观测区间和观测频率的年化波动率为：</p><script type="math/tex; mode=display">annualized\ volatility=\sqrt{\sum_{i = 1}^N \frac{1}{N-1}(AR_i-\overline{AR})^2}·\sqrt{\frac{1}{d}}</script><blockquote><p>为什么是$\sqrt{1/d}$？这主要是因为我们假设AR是独立同分布的，而一年的总AR = 第1周AR+第2周AR+…+第52周AR（对数收益率，或者简单收益率的趋近。基本原理是$\lim_{x-&gt;0}ln(1+X) = X$）。在独立同分布的假设下，$\sigma(\sum{AR_i}) = \sqrt{1/d} *\sigma(AR_i)$</p></blockquote><p>以周净值数据为例，由于一年共有52周，可知$d = 1/52$,在计算出周频率的绝对收益后，即可计算指定观测区间内的标准差，然后乘以$\sqrt{52}或\sqrt{50}$。</p><h3 id="最大回撤"><a href="#最大回撤" class="headerlink" title="最大回撤"></a>最大回撤</h3><p>通俗来讲，如果一个策略很不幸在最高点进入，又不幸在最低点卖出，那么这个策略的收益即是最大回撤。最高点和最低点不一定是某个指定区间的头尾——指定区间只是划定了一个范围，在这个范围时间内（例如最近一年），很可能只是在某几天“一顿操作猛如虎”，就酿成了本年度的最大回撤惨案。<br>最大回撤的数据公式定义为：</p><script type="math/tex; mode=display">max\_drawdown = min_{j,i<=j}(X_j - X_i) = min_{j}(X_j - max_{i<=j}X_i)</script><p>看到这里是不是开始晕乎乎了呢？实际上只要一步步分解下来，实现计算最大回撤的算法并不难：</p><ol><li>指定一个时间范围，例如最近一年。在这个时间范围内，投资者可以随时买入，也可以随时卖出。</li><li>对每个观测点j，都计算从指定时间起点开始任意时点入场、并假设在j点卖出的收益，即计算$(X_j-X_1),(X_j-X_2),…(X_j-X_{j-1}$，然后找到这些收益中的最低收益对应的时点i。</li><li>对所有j都进行了第2步运算后，找到最低中的最低，以及该最低点对应的i*和j*，其中i*就是最大回撤的起始点，j*就是最大回撤的终止点，$\frac{X_{j<em>}-X_{i</em>}}{X_{i*}}$即为指定时间范围内的最大回撤率。</li></ol><h3 id="卡玛比率"><a href="#卡玛比率" class="headerlink" title="卡玛比率"></a>卡玛比率</h3><p>如前文所述，卡玛比率是一种类似夏普比率的收益回报比，常用于衡量产品的性价比。相比夏普比率，卡玛比率更注重每单位风险的绝对收益，与此对应，该指标选择最大回撤衡量风险。在完成绝对收益和最大回撤的计算后，卡玛比率的计算就极为轻松了。</p><script type="math/tex; mode=display">calmar ratio = \frac{区间AR}{区间max\_drawdown}</script><h3 id="滚动指标"><a href="#滚动指标" class="headerlink" title="滚动指标"></a>滚动指标</h3><p>可以看到，在计算上述指标时，一个隐性的问题是：我们想在哪个时间范围考察这些指标？只考虑近一年的情况显然是不够的，而即使延伸到最近k年的计算结果，也是站在当前这一时点对所有历史进行回溯。一个更为动态的视角是想象自己站在每个历史上的时点，回顾该时点之前的历史，而这就是滚动指标的意义。对于滚动指标的计算，一般首先要指定一个窗口，例如1年，然后在每个时点去计算“近1年超额收益率”等指标，从而绘制出一条以时间为横轴的曲线，而非仅仅得出一个数值。</p><h2 id="python代码实现"><a href="#python代码实现" class="headerlink" title="python代码实现"></a>python代码实现</h2><p>假设我们将周净值数据存储在<code>nv_ts</code>这一个DataFrame对象中，具体包括：以周为单位的时间索引，产品对应净值和基准指数的对应净值。下面分步实现上述四个指标在1年范围内的计算。<br>为了代码上实现方便，这里直接使用empyrical包直接获得最大回撤。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime, timedelta</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt </span><br><span class="line"><span class="keyword">from</span> empyrical <span class="keyword">import</span> max_drawdown</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算产品和基准指数的周收益率（简单形式）</span></span><br><span class="line">nv_ts[<span class="string">'周产品收益'</span>] = nv_ts[<span class="string">'产品净值'</span>].pct_change()</span><br><span class="line">nv_ts[<span class="string">'周基准收益'</span>] = nv_ts[<span class="string">'基准指数'</span>].pct_change()</span><br><span class="line"><span class="comment"># 计算产品和基准指数近1年的收益率</span></span><br><span class="line"><span class="comment"># 截取最近一年的数据</span></span><br><span class="line">start_date = datetime.now()-timedelta(days = <span class="number">365</span>)</span><br><span class="line">nv_ts_one_year = nv_ts[nv_ts.index&gt;start_date]</span><br><span class="line">product_AR = nv_ts_one_year[<span class="string">'产品净值'</span>].iloc[<span class="number">-1</span>]/nv_ts_one_year[<span class="string">'产品净值'</span>].iloc[<span class="number">0</span>]<span class="number">-1</span></span><br><span class="line">baseline_AR = nv_ts_one_year[<span class="string">'基准指数'</span>].iloc[<span class="number">-1</span>]/nv_ts_one_year[<span class="string">'基准指数'</span>].iloc[<span class="number">0</span>]<span class="number">-1</span></span><br><span class="line"><span class="comment"># 计算近一年的超额收益</span></span><br><span class="line">product_ER = product_AR-baseline_AR</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算近一年年化波动率</span></span><br><span class="line">volatility = nv_ts_one_year[<span class="string">'周产品收益'</span>].std(ddof = <span class="number">1</span>)*sqrt(<span class="number">52</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算近一年最大回撤</span></span><br><span class="line">max_dd = - max_drawdown(nv_ts_one_year[<span class="string">'周产品收益'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算卡玛比率</span></span><br><span class="line">calmar_ratio = product_AR/max_dd</span><br></pre></td></tr></table></figure></p><h3 id="最大回撤计算"><a href="#最大回撤计算" class="headerlink" title="最大回撤计算"></a>最大回撤计算</h3><p>除了使用现成的第三方工具以外，也可以自行计算最大回撤，从而帮助我们更好的理解最大回撤的公式和意义。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_max_dd</span><span class="params">(nv_ts)</span>:</span></span><br><span class="line">  <span class="comment"># 先找终止点</span></span><br><span class="line">  j = np.argmax(np.maximum.accumulate(nv_ts)-nv_ts)</span><br><span class="line">  <span class="comment">#np.maximum.accumulate()是指对每个点计算从0到这个点这一子序列中的最大值，然后通过argmax找到使这一差值最大的时间点j</span></span><br><span class="line">  <span class="comment"># start of the period</span></span><br><span class="line">  i = np.argmax(nv_ts[:j])在终止前的最高点就是最大回撤的开始时刻</span><br><span class="line">  <span class="comment"># 计算最大回撤率</span></span><br><span class="line">  max_dd = nv_ts[j]/nv_ts[i]<span class="number">-1</span></span><br><span class="line">  <span class="keyword">return</span> i,j,max_dd</span><br></pre></td></tr></table></figure></p><h3 id="关于滚动指标的实现"><a href="#关于滚动指标的实现" class="headerlink" title="关于滚动指标的实现"></a>关于滚动指标的实现</h3><p>对于滚动指标而言，最重要的是将pandas的rolling()与上面的函数相结合，具体将在之后另一篇关于rolling()方法的blog中详细探讨，此处暂略。</p><h2 id="参考资料链接"><a href="#参考资料链接" class="headerlink" title="参考资料链接"></a>参考资料链接</h2><p><a href="https://stackoverflow.com/questions/22607324/start-end-and-duration-of-maximum-drawdown-in-python" target="_blank" rel="noopener">Start, End and Duration of Maximum Drawdown in Python</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在做私募基金评价时，我们会使用不同的指标来量化该基金产品在各个维度上的表现。常见的四个指标包括超额收益率（衡量收益），波动率、最大回撤（衡量风险），卡玛比率（性价比）。其中卡玛比率类似常见的夏普比率，但具体到私募基金而言，由于私募基金相比公募基金更强调绝对收益，故使用绝对收
      
    
    </summary>
    
    
      <category term="编程与技术" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Python" scheme="https://v-swye.github.io/kanaeba/tags/Python/"/>
    
      <category term="金融" scheme="https://v-swye.github.io/kanaeba/tags/%E9%87%91%E8%9E%8D/"/>
    
  </entry>
  
  <entry>
    <title>stata分块处理大型文件</title>
    <link href="https://v-swye.github.io/kanaeba/2019/10/20/stata%E5%88%86%E5%9D%97%E5%A4%84%E7%90%86%E5%A4%A7%E5%9E%8B%E6%96%87%E4%BB%B6/"/>
    <id>https://v-swye.github.io/kanaeba/2019/10/20/stata%E5%88%86%E5%9D%97%E5%A4%84%E7%90%86%E5%A4%A7%E5%9E%8B%E6%96%87%E4%BB%B6/</id>
    <published>2019-10-20T09:37:00.000Z</published>
    <updated>2019-10-20T09:55:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>当需要处理大型文件时，使用python pandas包的chunksize或者iterator会非常方便，但stata相对来说就比较蠢笨。虽然正常人都不会用stata来做data cleaning的工作，但不可避免有时replicate某些大牛的文章时，仍然会坚持使用stata来做数据清洗，此时，超大的数据文件不免让人头疼，特别是Stata还有报错后就得重新运行的坑爹机制。那么废话不多说，下面来看看如何使用Stata处理大型数据文件吧。</p><h2 id="将文件分块"><a href="#将文件分块" class="headerlink" title="将文件分块"></a>将文件分块</h2><p>和python不同，stata需要我们自己先将大型文件（支持csv, txt等）划分成多个小文件。首先安装对应工具：<br>需要安装的对应工具为：chunky<br><code>ssc install chunky</code><br>然后，cd路径到我们要保存chunked files的地方，例如：<br><code>cd &quot;chunk files&quot;</code><br>然后运行文件分割指令：</p><ol><li>返回文件的头5行，确认数据无误：<code>chunky using filename, peek(5)</code></li><li>分析分块大小，为接下来确认每个分块文件的大小和最终数量做准备，该命令会返回不同分块大小情况下最终的文件个数等基本估计情况：<code>chunky using filename, analyze</code></li><li>根据2的结果确认每个分块文件的最适合的大小，进行实际分块操作，这里假设按每个文件1000M分块，分块结果的文件命名为chunk_0001.txt（类推）：<code>chunky using filename, chunksize(1000m) header(include) stub(chunk_) replace</code></li><li>运行时注意运行过程在—more—中，点击才能看到。header指令包括：include（使用csv中的第一行作为变量名），none（csv中第一行不是变量名称），skip（跳过csv第一行）</li></ol><h2 id="批量处理分块文件"><a href="#批量处理分块文件" class="headerlink" title="批量处理分块文件"></a>批量处理分块文件</h2><p>下面对分块文件进行批量处理，注意这里先把file名中00的部分去掉：<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">forv</span> i = 1/<span class="keyword">n</span>&#123;</span><br><span class="line">    <span class="keyword">clear</span></span><br><span class="line">    import delimited using <span class="string">"chunk_`i'.txt"</span></span><br><span class="line"><span class="comment">    * some codes and orders</span></span><br><span class="line">    <span class="keyword">save</span> <span class="string">"./output/result_`i'.dta"</span>, <span class="keyword">replace</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="合并处理完成的结果"><a href="#合并处理完成的结果" class="headerlink" title="合并处理完成的结果"></a>合并处理完成的结果</h2><p>最后，将处理得到的结果纵向合并：<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> <span class="string">"./output/result_1.dta"</span>, <span class="keyword">clear</span></span><br><span class="line"><span class="keyword">forv</span> i = 2/<span class="keyword">n</span>&#123;</span><br><span class="line">    <span class="keyword">append</span> using <span class="string">"./output/result_`i'.dta"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">save</span> <span class="string">"./output/result_final.dta"</span>, <span class="keyword">replace</span></span><br></pre></td></tr></table></figure></p><p>最后再让程序自动删除处理过程中生成的临时文件：<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">forv</span> i = 1/<span class="keyword">n</span>&#123;</span><br><span class="line"><span class="keyword">erase</span> <span class="string">"chunk_`i'.txt"</span></span><br><span class="line"><span class="keyword">erase</span> <span class="string">"./output/result_`i'.dta"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>大功告成！</p><h2 id="补充：截取大型文件的k行"><a href="#补充：截取大型文件的k行" class="headerlink" title="补充：截取大型文件的k行"></a>补充：截取大型文件的k行</h2><p>首先安装chewfile: <code>ssc install chewfile</code><br>然后读取并保存到指定文件：<code>chewfile using filename1, begin(100) end(1400) save(filename2) replace</code><br>这里指定了截取100-1400行的数据。如果只指定开头或结尾，使用begin(.)或者end(.)即可。</p><p><a href="https://stata-club.github.io/%E6%8E%A8%E6%96%87/20170116/" target="_blank" rel="noopener">参考链接</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;当需要处理大型文件时，使用python pandas包的chunksize或者iterator会非常方便，但stata相对来说就比较蠢笨。虽然正常人都不会用stata来做data cleaning的工作，但不可避免有时replicate某些大牛的文章时，仍然会坚持使用sta
      
    
    </summary>
    
    
      <category term="编程与技术" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据清洗" scheme="https://v-swye.github.io/kanaeba/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"/>
    
      <category term="Stata" scheme="https://v-swye.github.io/kanaeba/tags/Stata/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记：熊镇</title>
    <link href="https://v-swye.github.io/kanaeba/2019/10/20/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%86%8A%E9%95%87/"/>
    <id>https://v-swye.github.io/kanaeba/2019/10/20/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%86%8A%E9%95%87/</id>
    <published>2019-10-20T07:34:08.000Z</published>
    <updated>2019-10-20T13:58:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>从主线故事来看，《熊镇》实在是一本乏味的书。如果一句话就能写完的故事随便扩展成几十万字、再加上非常discursive的群像剧手法就能写一本畅销书的话，那这个世界可以称得上疯狂了。然而，巴克曼绝非哗众取宠之辈——翻完主线、乏善可陈，是第一遍，再回头时，却不得不为这些支离破碎的“片刻”间千丝万缕的联系所折服。</p><blockquote><p>体育带给我们的只有片刻。但是，彼得，人生除了片刻还剩下些什么？</p></blockquote><h2 id="冲突"><a href="#冲突" class="headerlink" title="冲突"></a>冲突</h2><p>熊镇只是个安静、逐渐没落的北欧小镇，然而，正如寂静的冰面上也承载着让人热血沸腾的冰球运动一般，有人的地方，冲突总是在暗流涌动。</p><blockquote><p>冲突中发生的第一件事情是：我们会选边站，因为这比在脑海里同时保持两种思路容易。发生的第二件事情是：我们会搜寻那些证实我们想法的证据，那样最舒服，能让人生一如往常过下去。第三件事情是：我们将我们的敌人去人性化。要做到这一点，有很多种方式，但最简单的莫过于将她的名字除掉。</p></blockquote><h3 id="经济冲突"><a href="#经济冲突" class="headerlink" title="经济冲突"></a>经济冲突</h3><p>熊镇的传统就是冰球。这种一个群体自发的在某个时刻选择标签化自己的行为似乎和个人追求小众爱好以试图distinct themselves、或是国际贸易中国家寻找自身的specialization并没有太大的差别。一旦这种自发的身份认同获得群体的肯定，就会固化成为传统，并且除非出现根本原则上的动摇，它很难再发生多大的改变。熊镇把一切都寄托在冰球上——你为冰球付出一切，冰球便会回报给你一切——新的体育馆，人口流入，经济增长。这种将利益与体育勾连的想法自然将体育的意义引入某种不可控制的方向：资本是贪婪的，不仅贪图份量，更贪图速度。绝大多数为球会提供资金的赞助商都不是为了做慈善，他们需要赢来获得经济的利润。在这种氛围下，无论是出于对小镇经济的责任、还是纯粹对理想结果的追求，“赢”这个字，将会无时无刻不以“焦虑”的形态压在总监、教练、球员、家长和观众们的心上。可以说，这种来自资金链顶端的冲突将自然蔓延至下游的每一个节点和每一段节点连线，而这些节点和连线便谱写了这段短暂时光里小镇发生的故事。</p><h3 id="价值观冲突"><a href="#价值观冲突" class="headerlink" title="价值观冲突"></a>价值观冲突</h3><p>对于一个体育团队而言，教练的重要性不言而喻。在技术上，老派的苏恩与新星戴维之间并没有多大的差别，两人对冰球的热爱绝不会低于另一方，差别只在于，二人对团队的教育观念大相径庭。苏恩是熊镇的传统，在他的世界里，成熟度和天赋对职业冰球来说一样重要。飞向天空的气球的关键不在于飞得有多快，而在于绳线有多长。与之相反，而戴维则强调明星化的团队建设，更衣室的玩笑话证明他并不是个冷漠无情的男人，但他教会那些男孩“我们要赢，我们是熊镇的熊”。</p><blockquote><p>你想被人喜欢吗？很简单，只要成为赢家就行了。因此，戴维不计一切代价要成为赢家。</p></blockquote><p>即使戴维对胜利的追求是出自他对冰球的纯粹热爱，但这种对绝对成果的追求自然受到现代资本的欢迎，观众也不可能厌倦一支总是胜利的冰球队——他们来看比赛绝不是来看自己支持的球队是怎样输掉的。赢家即使极端自私、毫无同理心，没关系，只要他们获胜，我们就喜欢他们。</p><blockquote><p>“我父母对冰球不感兴趣。”班杰问：“他们到底对什么感兴趣？”凯文回答：“成功。”</p></blockquote><p>这种对成功结果的绝对追求是错误的吗？这种问题很难回答，而且当对成功如痴如醉的膜拜已经渗透进全世界每一个焦虑的角落时，当我们自身也深陷其中时，谁也不知道强调绳线长度还能不能重新回到潮流，也没有勇气轻易偏离既定轨迹。</p><h3 id="成与败的冲突"><a href="#成与败的冲突" class="headerlink" title="成与败的冲突"></a>成与败的冲突</h3><p>然而，胜利真的可以拥有一切优先权吗？拥有正式球衣的球员成为胜利者的团队，精英的光环赋予他们在学校、在小镇的特权。不可否认，他们在没日没夜的训练付出的汗水令人敬佩不已，他们对冰球运动的热爱、对团队的忠诚都闪耀着青少年特有的充满希望的光芒，但从未有人教导他们如何去对待失败者，这群男生总是听到：他们有一堆不属于他们本身的特质，他们是熊，是赢家，拥有不坏金身。在他们眼里，只有赢家值得敬佩，而对弱者的怜悯大概是女性才会做的事。不仅成功者不乐于多看那些无法证明自己的人一眼，就是失败者本人也只顾怨愤上帝的不公，自发地在自己与成功者之间划定界限，完成权力的分配。当亚马被选入球队时，他的好友阿札就是其中的一员。这不一定完全是失败者自己的问题——当社会从小便为你指明了成功的唯一道路，而你恰好无法再继续向前行走时，任何一个人都很难笑着目送昔日旅伴大步迈向峰顶。</p><p>胜利，真的可以为一切让路吗？</p><h3 id="性别冲突"><a href="#性别冲突" class="headerlink" title="性别冲突"></a>性别冲突</h3><p>某种程度上，英雄主义与性别歧视或许有一定联系。女性天生在力量上的弱势表明她们几乎很少能在大部分制造“英雄”的领域崭露头角，而熊镇甚至没有女冰球队。因此，熊镇对女性以及她们对冰球态度的理解十分扭曲也就不奇怪了。如果你在熊镇却不爱冰球，那你显然是比较奇怪的物种。但是，对女性而言，这种爱并不被允许发展到产生干涉的地步。</p><blockquote><p>熊镇非常欢迎喜爱体育活动的女孩，但不是以她的那种方式去喜欢。不要那么投入，投入到对男生们授课说明冰球规则和战术的地步。在他们看来，女孩们最主要应该对冰球选手感兴趣，而非冰球运动本身。</p></blockquote><p>这种潜移默化的观念为全文乏味的主线故事奠定了基础——强奸是一种可以被胜利掩盖的行为吗？在戴维看来，体育应该被隔离在一个纯粹的培养皿中，它不应与社会其他的任何物质发生反应，比如政治。然而，他却忘了，竞技本身产生于人，而人永远是社会的一部分，当你加入竞技时，你就与人和社会发生了联系。即使我们讴歌体育的纯粹性，我们也最多只能做到尽可能只保留体育与社会之间最基本的联系，而如果这种自发的克制并不能抑制其动摇社会原则的根基，那么体育是绝不可能重建原则的——体育只是社会的很小很小的一部分。无论这个社会会选择站在体育的一方，还是站在受害者的一方，这都不重要。重要的是要有人发声，要有人愿意参与进来，仔细聆听对方说了些什么，即使对方说的都是胡言乱语。只要有说出口的勇气，那么至少，观点和事实可以被“知道”，从而获得证伪或是证实的可能。</p><p>玛雅是幸运的。安娜选择过逃避，但最终还是选择了坚定站在朋友身边：“我和你对抗全世界！”</p><h2 id="遵从内心的声音"><a href="#遵从内心的声音" class="headerlink" title="遵从内心的声音"></a>遵从内心的声音</h2><p>冲突如何被处理？怎样的处理才是正确的？玛雅的结局是公正的吗？没有人知道。但作者一开篇就已经埋下了伏笔：</p><blockquote><p>诚实的人会遭他人背弃；然而，你还是要诚实。<br>友善的人会遭他人诽谤；然而，你还是要友善。<br>你做的所有善事，别人会在一夕间忘记；然而，你还是要做善事。<br>别人可以摧毁你建立的一切；然而，你还是要动手建立一切。<br>因为到最后，一切将会存在于你和上帝之间，<br>这和你与其他所有人都没有关系。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从主线故事来看，《熊镇》实在是一本乏味的书。如果一句话就能写完的故事随便扩展成几十万字、再加上非常discursive的群像剧手法就能写一本畅销书的话，那这个世界可以称得上疯狂了。然而，巴克曼绝非哗众取宠之辈——翻完主线、乏善可陈，是第一遍，再回头时，却不得不为这些支离破碎
      
    
    </summary>
    
    
      <category term="读万卷书" scheme="https://v-swye.github.io/kanaeba/categories/%E8%AF%BB%E4%B8%87%E5%8D%B7%E4%B9%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>读书笔记：基因传</title>
    <link href="https://v-swye.github.io/kanaeba/2019/10/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%9F%BA%E5%9B%A0%E4%BC%A0/"/>
    <id>https://v-swye.github.io/kanaeba/2019/10/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%9F%BA%E5%9B%A0%E4%BC%A0/</id>
    <published>2019-10-13T07:09:29.000Z</published>
    <updated>2019-10-13T08:57:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>从神学指引到科学解释，从解剖结构到身份定位，基因贯穿在漫长的历史中，指引人类发现它的秘密，学会认识人类自身。《基因传》犹如巨幅的历史画卷，将人类与自然的科学性斗争娓娓道来。像夏日困倦午后长辈讲的上世纪故事，晚上便忘了大半，却在无形中刻上印记。</p><h2 id="基因与想象"><a href="#基因与想象" class="headerlink" title="基因与想象"></a>基因与想象</h2><blockquote><p>人类的想象终将填补无知的空白。</p></blockquote><h3 id="从神学到科学"><a href="#从神学到科学" class="headerlink" title="从神学到科学"></a>从神学到科学</h3><p>人类总是有将无法解释的东西归因于某种不可知力量的倾向，似乎只要把这份责任依附在某个概念上，就可以心安理得地、无知而快乐地生存下去。18世纪末期，诸如自然史等学科主要由神职人员把持，而他们都刻意回避神创论的基础命题。神学不仅是一种信仰，更是对大众思想的把握——于是，正统神学研究不可能对神创论直接提出质疑，探索生命起源乃是大忌。然而同时，人类又总是会被强烈的好奇心推动着，向着脱离常轨的方向蠢蠢欲动，在极致的科学性和纯粹的社会性间摇摆。孟德尔和达尔文便是这类代表性的人物，这两位出现在所有生物教科书上的科学家为将生物学科从神学的禁锢中解放出来做出了卓越的贡献。</p><h3 id="抽象的基因起源"><a href="#抽象的基因起源" class="headerlink" title="抽象的基因起源"></a>抽象的基因起源</h3><p>但说到底，孟德尔和达尔文距离基因两个字还十分遥远。孟德尔启发贝特森和约翰森创造出“基因”这个词，有意思的是，“基因”的创造是完全抽象的。那时，没有人对基因的物质形态、物理与化学结构、位置、作用机制等有任何了解，“基因”只是被用来标注某种功能，其概念依附于这种功能的存在。</p><h2 id="DNA结构破译的启示"><a href="#DNA结构破译的启示" class="headerlink" title="DNA结构破译的启示"></a>DNA结构破译的启示</h2><h3 id="复合的力量"><a href="#复合的力量" class="headerlink" title="复合的力量"></a>复合的力量</h3><p>破解DNA结构的秘密可谓是人类科学历史上的举足轻重的重要里程碑之一。作为一名根本不专业的读者，对于DNA结构究竟如何，在读完后也依然停止在高中课本的认知水平上；真正让我有所感念的，是这一过程中“复合体系”的伟大力量。</p><p>血红蛋白的分子结构犹如四叶草、而中心部位则是可以通过铁元素与血液中氧分子相结合的血红素。这种物理结构决定了其可以与氧分子相互结合，并在需要释放时放松“叶片”，完成一次运输，为机体组织提供足够的氧气。从而，血红蛋白便拥有了其独特的生理功能——相比血浆溶解氧含量提高70倍的携氧量。就像血红蛋白的分子研究一般，这种物理到化学到生理的学科转化也发生在DNA破译的过程中。例如，起初威尔金斯就曾采用源自剑桥大学的生物物理学手段，包括晶体学与X射线衍射技术来拼接其三维立体结构。而“三联体”密码子的猜想则有着来自初等数学的启示——二联体只有16种组合（4乘4），显然不足以编码20种氨基酸；四联体有256种组合，远远超出编码20种氨基酸所需。<br>科学的每一次进步，都不会是一枝独秀的结果。</p><h3 id="从简单入手"><a href="#从简单入手" class="headerlink" title="从简单入手"></a>从简单入手</h3><p>秀丽线虫完美展现了“从简单到复杂”的研究思想。动物学家发现，秀丽线虫只要进入成熟期，就将具有固定的细胞数，这些固定的细胞数指向着新发现的门扉——如果每个蠕虫都具有相同数量的细胞，那么基因必然携带着决定每个细胞生死的指令。细胞计数的艰苦努力见证了反映细胞命运图谱的产生。</p><h2 id="基因与表现"><a href="#基因与表现" class="headerlink" title="基因与表现"></a>基因与表现</h2><p>在生物多样性如此丰富的世界里，基因绝不是唯一的决定因素。</p><h3 id="双重指令"><a href="#双重指令" class="headerlink" title="双重指令"></a>双重指令</h3><p>在观察线虫构建虫体的过程中，科学家已经发现了细胞所受的“双重指令”。即，来自细胞内部的基因指令和细胞间交互作用的外部指令。或许，当单细胞生物第一次进化为多细胞生物的瞬间，就已经隐喻了地球生命将走向多样化的图景。</p><blockquote><p>遗传学家安托万曾经用德尔斐之船的寓言来形容个体基因为自然界创造复杂性的过程。众所周知，人们用德尔斐神谕来思考水中泛舟船板腐烂的问题。随着船体出现破损，船板也被逐个换掉。等到10年之后，最初的船板已经荡然无存。然而船主却认为这还是同一条船。但是如果每个原始的物质元素都已被替换，那么现在这条船怎么可能跟原来那条船相同呢？ 答案在于“船”并非由船板制成，而是由船板之间的关系组成。如果你把一百张彼此堆叠的木板压实，那么就可以得到一堵厚实的木墙；如果将木板边对边钉在一起，那么就可以做成甲板。</p></blockquote><h3 id="数量与组合"><a href="#数量与组合" class="headerlink" title="数量与组合"></a>数量与组合</h3><p>交互作用在基因组功能的体现中甚至起到更大的作用。果蝇的基因组只有13601个基因，比线虫的基因数量少5000个，却构建出了结构更为复杂的生物体；人类与线虫拥有的基因数量均为2万左右，一般拥有23对染色体，比大猩猩、黑猩猩与猩猩等人猿细胞所拥有的24对染色体还少一对，但人类却能脱颖而出。人类与这些蠕虫或是谷物之间的区别并不在于基因数量的多少，而是在于其细胞内部基因网络的复杂性，懂得如何将有限的资源发挥到极致。</p><blockquote><p>重要的不是你拥有什么，而是你通过它实现什么。</p></blockquote><h3 id="环境的力量"><a href="#环境的力量" class="headerlink" title="环境的力量"></a>环境的力量</h3><p>生物教科书总是强调，表现型是基因与环境共同作用的结果。这一条在《基因传》中也被反复提及，但让我印象比较深刻的是作者的一段猜想——或许，你本拥有无风无浪的未来，然而生命中那些偶然的意外，例如因为突然冲来的自行车受到惊吓、不经意在路上崴了脚、中了彩票头奖、吃到一顿珍馐等等，这些些许的偶然在基因组上刻上某些标记，而标记的累积或许就能引发基因的突变，最后走向完全不同的人生轨迹。<br>又或许，读完这本书，已在不知不觉中产生了某些不同。</p><h3 id="基因记忆"><a href="#基因记忆" class="headerlink" title="基因记忆"></a>基因记忆</h3><p>人类的基因组铭刻着许多历史，例如古代病毒的片段——尽管它们大多数已经失活或沉默。这种历史性帮助我们追根溯源。胚胎线粒体全部源自母系，并且几乎不会发生重组，使其得到完整的代际传递，而这种传递性意味着追溯人类起始的祖先成为可能。这种众生之母的概念令人产生无尽遐想，在人类遗传学研究中，她被称为“线粒体夏娃”。其他一些对于“遗传记忆”的研究也发现，饥荒幸存者的子孙更容易发生代谢性疾病，基因与环境的交互作用不仅改变了表型，也可能进一步将这种变化融入了更为深层次的基因组之中。这种理论挑战着达尔文进化论的本质特征。</p><blockquote><p>基因组与表观基因组存在的意义在于，它们可以跨越细胞与世代的时空来传承相似性与历史记忆。而基因突变、基因重组与记忆消除则可以拮抗这些力量，并且推进差异、变化、畸形、天赋与再造的产生，同时在继往开来的过程中为更加辉煌的明天开辟崭新的道路。</p></blockquote><h2 id="基因、政治与社会"><a href="#基因、政治与社会" class="headerlink" title="基因、政治与社会"></a>基因、政治与社会</h2><h3 id="纳粹、苏俄与优生学"><a href="#纳粹、苏俄与优生学" class="headerlink" title="纳粹、苏俄与优生学"></a>纳粹、苏俄与优生学</h3><p>正如人类将自然与神学相捆绑一样，基因同样与政治社会密不可分。基因参与着人类的所有活动，而人类本就是社会性的动物。俄国革命或许就与遗传有很大关系，当时阿列克谢王子罹患遗传病的事实与其显赫的政治地位大相径庭，使其君主政权备受质疑。</p><p>优生学是人类在基因上走偏的标志性问题。在希特勒时代，纳粹提倡绝育以净化人民的基因库；进一步地，在私人医生卡尔·勃兰特的协助下，希特勒颁布了《严重遗传性与先天性疾病科学等级制度》，以此为契机开展了大屠杀式的安乐死计划，以全面清除遗传“缺陷”。在大屠杀期间，有600万犹太人、20万吉卜赛人、几百万苏联和波兰公民还有不计其数的同性恋者、知识分子、作家、艺术家以及持不同政见者在集中营与毒气室中惨遭杀害。</p><p>马丁·尼莫拉（Martin Neimöller）是德国著名神学家，他在那篇广为流传的忏悔书中总结了纳粹主义暴行的演变过程：</p><blockquote><p>起初他们追杀共产主义者，我没有说话—— 因为我不是共产主义者；<br>后来他们追杀工会会员，我没有说话—— 因为我不是工会会员；<br> 接着他们追杀犹太人，我没有说话—— 因为我不是犹太人；<br> 最后他们奔我而来——那时已经没有人能为我说话了。</p></blockquote><p>与纳粹相反，苏联则走向了另一个极端。纳粹相信任何人只能是任何人，如果产生了缺陷，那么就只能清除掉；而苏联左翼则相信，任何人都能被改造为其他人，民众需要被净化的不是基因，而是大脑，政府应当对全体人民进行再教育、抹去从前的自我。这些人类历史上的悲剧，应时刻警醒着我们避免重蹈覆辙。现代优生学便致力于摆脱过往的罪恶，产前检查与选择性人工流产成为选择性防止遗传病的手段。</p><h3 id="DNA伦理问题"><a href="#DNA伦理问题" class="headerlink" title="DNA伦理问题"></a>DNA伦理问题</h3><p>极致的科学追求对DNA重组的想法只会停留在科学层面，然而，人类与其他生物最大的不同是意识——伦理问题会随着科学的进步速度加快而凸显。DNA双螺旋结构的发现者之一沃森便反对对科学家开展重组DNA实验加以严格限制，主张科学家无约束进行实验。就像美国国家科学基金会负责人艾伦·沃特曼于1962年所写的那样：</p><blockquote><p>纯粹的科学并不在意发现导致的结果……其信徒只对探索真理感兴趣。</p></blockquote><p>阿西洛马会议在这一点上具有重要意义：科学家们反思自己使用技术的危害性，并且积极寻求对自身工作进行规范和约束。</p><h3 id="性别与身份认知"><a href="#性别与身份认知" class="headerlink" title="性别与身份认知"></a>性别与身份认知</h3><p>正如作者指出的那样，生物学特征事实上涉及人类的身份问题，即如何从文化、社会与政治角度来定义、分类和理解人类自身。性别认知就是基因与社会身份之间交互的重要问题之一。过去，一般认为在表观上，男性与女性在解剖与生理上存在很大差异，基因是决定这些差异的根本原因，而这些差异会介入个体的文化与社会建构。然而，这种认知实际上并不准确。出生时具有XY染色体的”遗传学男性”就曾是这类问题的受害者之一，由于其生殖器解剖结构发育不良,在出生时会被认定为女性,而这些男性绝大多数都在童年经历了性别焦虑与抑郁的折磨。<br>基因在性别认定上的影响力远超任何因素，改变文化或社会背景几乎无法对性别特征造成实质性的影响。在医学上已经达成了一种共识，即判断儿童性别应该以其染色体为准，而与解剖变异和外在差异无关。</p><h2 id="科学研究之路"><a href="#科学研究之路" class="headerlink" title="科学研究之路"></a>科学研究之路</h2><p>在观赏人类基因发现的历史画卷时，作为一名伪科研学僧，也感慨科研过程中果然存在共通的某些问题。科研也讲究天时地利人和，三者缺一不可。孟德尔和达尔文都长期不得志，而埃弗里曾获得三次诺贝尔奖提名，但是由于艾纳·哈马斯登这位极具影响力的瑞典化学家拒不相信DNA能携带遗传信息，因此埃弗里终生都没能获得诺贝尔奖。不过，放长远来看，真正有意义的发现总会在某个时刻，得到有意义的、如潮般的积极回应。</p><blockquote><p>就像音乐家、数学家以及优秀运动员一样，早年成名的科学家往往容易智穷才尽。他们失去的不是创造力，而是持之以恒的毅力：科学研究是一种比拼耐力的“运动”。为了获得某项具有指导意义的结果，可能需要进行成百上千次失败的实验，其实这就是自然与人类之间的斗争。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从神学指引到科学解释，从解剖结构到身份定位，基因贯穿在漫长的历史中，指引人类发现它的秘密，学会认识人类自身。《基因传》犹如巨幅的历史画卷，将人类与自然的科学性斗争娓娓道来。像夏日困倦午后长辈讲的上世纪故事，晚上便忘了大半，却在无形中刻上印记。&lt;/p&gt;
&lt;h2 id=&quot;基因与
      
    
    </summary>
    
    
      <category term="读万卷书" scheme="https://v-swye.github.io/kanaeba/categories/%E8%AF%BB%E4%B8%87%E5%8D%B7%E4%B9%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>读书笔记：当我谈跑步时我谈些什么</title>
    <link href="https://v-swye.github.io/kanaeba/2019/09/28/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%BD%93%E6%88%91%E8%B0%88%E8%B7%91%E6%AD%A5%E6%97%B6%E6%88%91%E8%B0%88%E4%BA%9B%E4%BB%80%E4%B9%88/"/>
    <id>https://v-swye.github.io/kanaeba/2019/09/28/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%BD%93%E6%88%91%E8%B0%88%E8%B7%91%E6%AD%A5%E6%97%B6%E6%88%91%E8%B0%88%E4%BA%9B%E4%BB%80%E4%B9%88/</id>
    <published>2019-09-28T08:20:36.000Z</published>
    <updated>2019-09-28T14:26:17.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Pain is inevitable. Suffering is optional. </p></blockquote><p>村上春树的文字总是有一种云淡风轻般就能戳中内心深处的力量。特别是作为同款跑者而言，能引发共鸣的思考更多了。当然，就长度来说，完全比不上村上马拉松级的练习，但强风中飘荡的思绪却可说是略同的。</p><p>即使不刻意运动，一个人也能活下去；但运动对于大多数人维持健康的体魄来说仍属必要。这在年轻人的意识或许还感知不到，随着年月增长，时光总会悄悄留下些残酷的痕迹，运动，便是与时间刻刀的抗衡。可以选择的运动多种多样，决不能谈运动便是跑步，或是冲动之下在健身房办下“洗澡卡”。每个人自有其适应的运动；在村上看来，跑步适合的是什么样的人呢？第一，要性格匹配。与一些集体性的活动不同，跑步基本上属于一个人的狂欢，与他人的交往在社会中的重要性不言而喻，但自己的沉默时间亦是精神健康的必修课，而跑步过程中，则是一个人独处的好时光。第二，要体质跟得上。心肺功能欠佳、爆发力强的人，要强硬让他从短跑道换成漫长的绕圈显然不够现实，另一方面，跑者（比如我）也常常抱着为了避免长肉而不得不为之心态。如村上所说，易胖体质的人看着怎么吃都不发胖的人，心里常怨念上帝的不公；然而长期来看倒未必比那些怎么吃都不胖的人更获上帝青睐——正是易胖体质才能敦促人勤加锻炼，于是老来反而更健康一些。第三，是要与人生信条匹配。跑步是对肉体的磨练也是对意志的挑战。正是这种神经与肌肉的惯性，为跑者提供了人生路途的立足点。村上自己描述自己的性格是“属于比较执拗的性格，假如有什么事情未能做成，就会一直做到成功，否则便抛舍不下，心情也无法平静”，这种执拗与跑步正是相得益彰。</p><p>在一个人做跑步练习时，竞争性的缺乏使人只需关注自身的步调，一步一步，乐得轻松自在。大脑在一天的繁忙中短暂抽离，也可进行一些背诵类的工作——“一边几乎无意识地迈步，一边在大脑中依序排列词语，检验文章的节奏，设想词句的韵律。就这样一面将意识放置于别处，一面放脚奔跑，便能毫不费力地以自然的速度跑很久很久。只不过在脑子里自说自话，有时一不留神做出表情、摆出姿势来，从对面跑过来的人便一脸莫名其妙。”然而，当走上比赛跑道或是为了准备比赛而寻找突破点时，心情就完全不同了。“被别人重重包围时，即使你不想这么做，不由得也会发力。跟着众人一起“预备，跑！”地去赛跑，本是非常愉快，竞争本能却会不知不觉露出锋芒来。”而且不可避免地，无法看到进步可能的挫败感将伴随着突破式训练而来。这或许是任何一种带有目标的旅程都不得不触发和跨越的拐点，比如前面三十分钟还觉得自信满满、精力十足，一旦计时器超过30这个数字，全身就好像再也不听使唤，四肢、关节甚至内脏器官都在叫嚷着要求休息。</p><blockquote><p>在我与跑步之间，这样一种徐缓的倦怠期前来造访了。其间有付出的努力得不到报偿的失望，有理应敞开的门户不知何时却被关上的茫然。我称这些为“跑者蓝调”。</p></blockquote><p>而跑步究竟在追求什么？并不是专业运动员，只为保持体重的话也无需去定什么挑战目标。对长跑选手而言，在跑全程时能否感到自豪或类似自豪的东西，可能才是最重要的。只要能起越过去的自己，哪怕只是一点。尽力，最大程度的忍耐。我最喜欢村上君的一点，大约就是这样尽人事的认真，和知天命的豁达。</p><p>刻意经历痛苦，然后从中发觉活着的事实。这可能是克服一切挫折、挑战，所目指す唯一の根本目標です。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Pain is inevitable. Suffering is optional. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;村上春树的文字总是有一种云淡风轻般就能戳中内心深处的力量。特别是作为同款跑者而言，能引发共鸣的思考更多了。当然，就长度
      
    
    </summary>
    
    
      <category term="读万卷书" scheme="https://v-swye.github.io/kanaeba/categories/%E8%AF%BB%E4%B8%87%E5%8D%B7%E4%B9%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>读书笔记：乌合之众</title>
    <link href="https://v-swye.github.io/kanaeba/2019/09/22/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E4%B9%8C%E5%90%88%E4%B9%8B%E4%BC%97/"/>
    <id>https://v-swye.github.io/kanaeba/2019/09/22/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E4%B9%8C%E5%90%88%E4%B9%8B%E4%BC%97/</id>
    <published>2019-09-22T06:34:35.000Z</published>
    <updated>2019-09-22T07:02:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>在世界逐渐走向失序的暗潮里，翻出这本16年就沉在Kindle里的书。记得在iBooks还能用的时候，也在苹果上买过一本，名著就是这样，买了一本又一本，也不见得有勇气翻开几次。不过实际上，经典未必都是难啃的大部头，比如这部短小精悍的《乌合之众》。</p><blockquote><p>在追求梦想的过程中，从野蛮走向文明，再随着梦想力量的失去，走向衰落和死亡，这就是一个民族的生命循环。</p></blockquote><h2 id="认识群体"><a href="#认识群体" class="headerlink" title="认识群体"></a>认识群体</h2><h3 id="群体概念"><a href="#群体概念" class="headerlink" title="群体概念"></a>群体概念</h3><p>群体是一个与个体相对的概念。个体是理性的，而群体则是非理性的。勒庞认为，种族的文明程度，或者说情绪化程度，决定了群体的非理性程度。这虽然是种族主义的陈旧偏见，但不可否认的是，情绪而非物理存在才是群体定义的本质。群体产生源于思想与情绪的同一导向，与其说在讨论群体，不如说是在讨论心理群体的特征。</p><h3 id="群体的特征"><a href="#群体的特征" class="headerlink" title="群体的特征"></a>群体的特征</h3><ul><li><strong>匿名性</strong>：在群体的掩护下，个人获取了势不可挡的心理感受，使得放纵本能成为可能。这种匿名性显然是群体失控的潜在引子。</li><li><strong>传染性</strong>：传染性决定了群体的倾向，同时推动个体愿意为了集体利益而牺牲、放弃个人利益。</li><li><strong>暗示性</strong>：群体暗示下，个体的行为表现甚至可能与其独处时的表现完全相反。不过，虽然群体智力低于孤立个体，但其情绪和行为所产生的表现形式及后果未必更坏。比如，在群体的号召下，个人可能更愿意慷慨解囊、热心慈善，他们在群体中获得了更高的认同感。</li></ul><h2 id="群体观念"><a href="#群体观念" class="headerlink" title="群体观念"></a>群体观念</h2><p>要明白如何巧妙地“领导”群体，首先要清楚观念如何在群体中传播，特别是基本观念。勒庞将群体观念分为两种，一种是短时的观念，而另一种则是在环境、遗传和舆论等要素影响下形成的基本观念。在观念的形成和传播过程中，群体的力量也在不断被放大。</p><h3 id="观念的传播"><a href="#观念的传播" class="headerlink" title="观念的传播"></a>观念的传播</h3><p>观念传播埋伏于诸如种族、传统、时间、制度和教育等间接因素，而爆发于某个事件或是特殊时间点产生的直接因素。因此，领导者需要意识到，群体只擅长低级推理：将表面关联的事物结合在一起；或是将特殊事件即刻一般化。经年的事故死亡并不比一次具体、详细描述的实验室爆炸更牵动人心。这是因为，与群体极为低下的推理能力相反，群众伟大的想象力可以构筑出强大的“想象共同体”。因而，领导者想要提出的观念必须足够简明、形象，最好以“断言”的形式出现，然后再加以重复和感染，打动和引诱比纯粹理性的公平制度有效得多。而感召力的强弱则主要取决于成功所带来的名望。观念一旦形成，便很难改变，然而却有一点必须时刻注意：一旦失去名望，观念很可能迅速分崩离析。因此，那些历史上长期保持名望的人，为了让群众信仰，总是注意保持距离，维持自身的神秘感。</p><h3 id="教育的力量"><a href="#教育的力量" class="headerlink" title="教育的力量"></a>教育的力量</h3><p>另一点令人印象深刻的是勒庞关于教育的探讨。教育方式影响着人的推理、判断和想象能力，也就是说，也潜在地影响着“一个民族的文明程度”。勒庞对英美社会的教育赞赏有加，而对形成乌合之众的教育方式不以为然：死记硬背的教育只培养出盲目服从的学生，所教授的内容无助于社会，不过是产生持有文凭的失业者。讽刺的是，这种教育下形成的乌合之众，倒的确是更有助于维持稳固的统治。</p><blockquote><p>始终支配着群体心灵的，不是对自由的渴求，而是对被奴役的渴求。</p></blockquote><h2 id="乌合之众"><a href="#乌合之众" class="headerlink" title="乌合之众"></a>乌合之众</h2><p>《乌合之众》对当前“群体无意识行为取代个体有意识行动”的社会流向提供了解释，指出历史上真正的动荡并非那些大事件，而是扎根群众思想底部的观念变化。这自然有助于我们理解历史上的群体性事件，然而到底是止步于此，还是反思个人在群体中所扮演的角色，或是用于钻研运用“大胜利、大奇迹、大罪行、大前景”引导群体的“帝王术”，或是选择更为高尚的道路、寻找人类群体失控与个体孤立之间的平衡点，则是“理性”个体需要自己追寻的答案。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在世界逐渐走向失序的暗潮里，翻出这本16年就沉在Kindle里的书。记得在iBooks还能用的时候，也在苹果上买过一本，名著就是这样，买了一本又一本，也不见得有勇气翻开几次。不过实际上，经典未必都是难啃的大部头，比如这部短小精悍的《乌合之众》。&lt;/p&gt;
&lt;blockquot
      
    
    </summary>
    
    
      <category term="读万卷书" scheme="https://v-swye.github.io/kanaeba/categories/%E8%AF%BB%E4%B8%87%E5%8D%B7%E4%B9%A6/"/>
    
    
      <category term="社会学" scheme="https://v-swye.github.io/kanaeba/tags/%E7%A4%BE%E4%BC%9A%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>后布雷顿森林时代</title>
    <link href="https://v-swye.github.io/kanaeba/2019/08/25/%E5%90%8E%E5%B8%83%E9%9B%B7%E9%A1%BF%E6%A3%AE%E6%9E%97%E6%97%B6%E4%BB%A3/"/>
    <id>https://v-swye.github.io/kanaeba/2019/08/25/%E5%90%8E%E5%B8%83%E9%9B%B7%E9%A1%BF%E6%A3%AE%E6%9E%97%E6%97%B6%E4%BB%A3/</id>
    <published>2019-08-25T13:26:32.000Z</published>
    <updated>2019-08-26T01:58:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>布雷顿森林体系II之后到来的是什么？</p><p>第一个全球化的黄金时代开始于19世纪，得益于金本位。政府将货币与黄金挂钩，以牺牲货币政策独立性的方式维持固定汇率和资本自由流动。然而，19世纪30年代的大萧条打破了这一微妙的平衡，各国货币竞争性贬值，愤怒的贸易伙伴增加关税反击，世界重回相互对立的通货区域。1944年，联盟国在新罕布什尔（New Hampshire）的布雷顿森林会议上再次尝试建立货币秩序（Bretton Woods Agreements）。此后，1944年7月到1971年间，布雷顿森林体系一直维持着货币运行规则。</p><p>参与国将他们的货币与美元挂钩（保留一定程度的浮动空间），而美元则与黄金挂钩。这一秩序仅持续了四分之一世纪。随着20世纪60、70年代美国贸易逆差累积、通胀率上升，黄金大量外流，对美元能否与黄金挂钩的质疑开始浮现。强烈缩紧财政和货币政策有助于恢复美元在海外的信誉，但却会给国内带来巨额成本。面对不得不在维护国内利益和全球货币系统稳定之间的抉择，尼克松放弃了美国在布雷顿森林体系中的承诺。1971年8月，美国的在任总统理查德·尼克松宣布结束战后经济秩序，停止将美元与黄金直接挂钩。</p><p>当前的货币体系常被称为第二代布雷顿森林体系（后布雷顿森林时代）。美元依然具有主导地位，世界商业贸易大部分以美元交易，美国经济政策影响着全球经济的方方面面。研究表明，强势美元抑制全球贸易，而紧缩的美国货币政策将使全球的金融环境恶化。在经过种种危机后，20世纪90年代开始，新兴经济体学会了以积累大量美元外汇储备来保护自身，并在2014年达到巅峰。超额的美元需求导致美元价格高估，增加了新兴市场出口商的竞争力。美国从此经历了长期的经常账户赤字：也就是说，美国的高额消费实际上由新兴世界的贷款提供融资，后者将其持有的美元用于投资美国资产。货币的流动，从外汇储备国（主要是中国）到美国，再从美国消费者回到外汇储备国，描绘出第二代布雷顿森林体系的大体面貌。</p><p>这一体系显然是不可持续的。美国不可能永远从海外借到钱，而长期的经常账户赤字使其出口产业付出代价。21世纪初，鲜有人预料到美国会厌倦自己在这一体系中的角色，而去工业化给美国社区带来的损害会使相关的政治家开始对从全球化中得到的好处产生怀疑。<br>当前的体系一度有希望改善全球失衡。欧洲和中国经济的整合与发展可能构筑多极世界，美元作为储备货币的需求随之下降，欧洲和中国的消费者将分担过去的美国消费者所承担的角色。然而，在过去十年的动荡中，投资者涌向美元安全资产，巩固了美元霸权地位。债务危机债务危机摧毁对欧元的信任。中国经济放缓使对人民币的信心下降，特朗普的螺旋式贸易和汇率战的威胁下，当前体系摇摇欲坠。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;布雷顿森林体系II之后到来的是什么？&lt;/p&gt;
&lt;p&gt;第一个全球化的黄金时代开始于19世纪，得益于金本位。政府将货币与黄金挂钩，以牺牲货币政策独立性的方式维持固定汇率和资本自由流动。然而，19世纪30年代的大萧条打破了这一微妙的平衡，各国货币竞争性贬值，愤怒的贸易伙伴增加关税
      
    
    </summary>
    
    
    
      <category term="宏观" scheme="https://v-swye.github.io/kanaeba/tags/%E5%AE%8F%E8%A7%82/"/>
    
  </entry>
  
  <entry>
    <title>Social Connectedness: JEP reading</title>
    <link href="https://v-swye.github.io/kanaeba/2019/08/17/Social-Connectedness-JEP-reading/"/>
    <id>https://v-swye.github.io/kanaeba/2019/08/17/Social-Connectedness-JEP-reading/</id>
    <published>2019-08-17T02:06:15.000Z</published>
    <updated>2019-11-27T06:29:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>This is a summary note for the following paper:</p><p>Bailey, M., Cao, R., Kuchler, T., Stroebel, J., &amp; Wong, A. (2018). Social connectedness: measurement, determinants, and effects. Journal of Economic Perspectives, 32(3), 259-80.</p><h2 id="Introduction-of-the-new-measure-SCI"><a href="#Introduction-of-the-new-measure-SCI" class="headerlink" title="Introduction of the new measure:SCI"></a>Introduction of the new measure:SCI</h2><p>the normalized total number of friendship links for each geographic pair.</p><h3 id="Construction-Method"><a href="#Construction-Method" class="headerlink" title="Construction Method"></a>Construction Method</h3><p>max: 1,000,000-&gt;Los Angeles Country, where people have the most friends with people from the same county.</p><p>for county <strong>pairs</strong> C1 and C2: if the total num of friendship links are c1 and c2 respectively, then the SCI of C1 and C2, denoted as idx1 and idx2, would be constrained to the following relationship:</p><script type="math/tex; mode=display">idx_1-idx_2 = c_1-c_2</script><p>total county pairs: 3,136.</p><h3 id="Relative-Probability-of-Friendship"><a href="#Relative-Probability-of-Friendship" class="headerlink" title="Relative Probability of Friendship"></a>Relative Probability of Friendship</h3><p>the relative probability of friendship is defined as:</p><script type="math/tex; mode=display">rp = \frac{idx_{ij}}{user_i*user_j}</script><p>Where $user_i$ represents the total Facebook users living in county i.</p><p>Some facts: </p><ul><li>the geographic concentration of the friendship network of Kern County is similar to the US average while San Francisco County’s friendship network is extremely geographically dispersed.</li><li>For the average(population-weighted) US county, 55.4 percent of friends live within 50 miles.</li></ul><h3 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h3><h4 id="Regression-Model"><a href="#Regression-Model" class="headerlink" title="Regression Model"></a>Regression Model</h4><ul><li>dependent variable Y: log of SCI between i and j</li><li>regression unit: county pairs</li><li>independent X: log geographic distance and other fixed effects</li></ul><h4 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h4><ol><li>geographic distance explains a significant amount of the cross-county-pair variation in social connectedness.</li><li>SC is often strongest with other counties within the same state.</li><li>The elasticity of social connectedness relative to geographic distance is less negative(or declines in terms of absolute value) as we include county-pairs that are progressively further apart. In other words, <strong>the appropriate elasticity depends on the geographic distances studied.</strong></li><li>Adding homophily factors barely affects the coefficients of other explanatory variables or the R^2.</li></ol><h4 id="Hierarchical-Agglomerative-Linkage-Clustering"><a href="#Hierarchical-Agglomerative-Linkage-Clustering" class="headerlink" title="Hierarchical Agglomerative Linkage Clustering"></a>Hierarchical Agglomerative Linkage Clustering</h4><p>Object: to form borders artificially by grouping together US counties with the aim of maximizing within-community social connectedness,  and then compare the artificial borders with the real state borders.</p><p>Grouping results: 20 distinct communities, all of which are spatially contiguous, a result of the strong dependence of social connectedness on geographic distance.</p><p>Comparison results: many of the community borders line up with state borders. However, some states are split into separate communities.</p><p>Possible explanation: </p><ul><li>physical obstacles: large rivers and mountain ranges</li><li>Military bases</li><li>Shale oil boom and in-migration</li></ul><p>Suggestion: study the economics/politics of US “regions” in terms of the social connectedness communities.</p><h2 id="Relationship-between-Diversity-and-Economic-Outcomes"><a href="#Relationship-between-Diversity-and-Economic-Outcomes" class="headerlink" title="Relationship between Diversity and Economic Outcomes"></a>Relationship between Diversity and Economic Outcomes</h2><h3 id="Facts-Diversity-and-Economic-Development"><a href="#Facts-Diversity-and-Economic-Development" class="headerlink" title="Facts: Diversity and Economic Development"></a>Facts: Diversity and Economic Development</h3><p>Geographic dispersion of friendship links is highly correlated with social and economic outcomes at county level.<br>Def. of socioeconomic outcomes: income, education, teenage birth rate, life expectancy, social capital, social mobility, etc. </p><p>Implication: controlling for the geographic concentration of social networks to minimize omitted bias when studying socioeconomic outcomes at the county level.</p><h3 id="Possible-Transmission-Channels"><a href="#Possible-Transmission-Channels" class="headerlink" title="Possible Transmission Channels"></a>Possible Transmission Channels</h3><h4 id="Within-US-Trade-Flows"><a href="#Within-US-Trade-Flows" class="headerlink" title="Within-US Trade Flows"></a>Within-US Trade Flows</h4><p>Trade flows data: state level.<br>Reg Y: log of the value of trade in 2012 between state pairs(i could == j)<br>Key X: log of geographic distance &amp; log of the SCI between state pairs(WA of county-level SCI measures).<br>Other reg X: fixed effects, dummy variables for own-state flows, dummy for adjacency. </p><p>Findings: </p><ul><li>SC is strongly correlated with between-state trade flows, even after controlling geographic distance.</li><li>Controlling for SC significantly reduces the estimated distance elasticities of trade. While the elasticities of SC to trade is not affected by adding fixed effect factors.</li><li>The geographic distance might be proxying for other factors affecting inter-state trade.</li></ul><h4 id="Patent-Citations"><a href="#Patent-Citations" class="headerlink" title="Patent Citations"></a>Patent Citations</h4><p>Why patent citations: a large empirical literature has relied on patent citations as a measure of <strong>knowledge spillovers.</strong><br>Construct dataset for observation: for each granted patent, observe all other patents that it cites.<br>Matching approach: match each citing patent with a non-citing patent issued at the same time and in the same technological calss to serve as a control.<br>In detail: for each citing patent, find all non-citing patents that fit the requirement stated below, and randomly draw one from the non-citing pool.<br>The final patent-citation pair: for each patent, if it cites N patents, then we have :<br>(original patent A - patent cited B - patent C that is matched to A but does not cite B)*N groups</p><p>Regression:<br>Reg Y: 1 if an issued patent i cites patent j and 0 otherwise.<br>Key X: log of geographic distance &amp; log of SCI between county pairs of the issued and cited patents<br>Other reg X: fixed effects for the technology classes and county pairs</p><p>Findings: SC explains marginally more of the variation in the probability of a patent citation than geographic distance.<br>Potential of the SCI data to help uncover the possible causal relationships behind these correlations. </p><h4 id="Migration"><a href="#Migration" class="headerlink" title="Migration"></a>Migration</h4><p>Reg Y: log of total migration between county pairs during 2013-2014.</p><p>Findings: SCI significantly explains migration between regions. Overall, individuals are more likely to move to counties where they already have frieds.</p><h2 id="Future-Exploration"><a href="#Future-Exploration" class="headerlink" title="Future Exploration"></a>Future Exploration</h2><ul><li>contagious illnesses and diseases</li><li>track whether measure of sentiment spread along social networks</li><li>relationships between transportation networks and social connectedness. e.g. potential demand for transportation links</li><li>testing theoretical models of network formation</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This is a summary note for the following paper:&lt;/p&gt;
&lt;p&gt;Bailey, M., Cao, R., Kuchler, T., Stroebel, J., &amp;amp; Wong, A. (2018). Social conn
      
    
    </summary>
    
    
      <category term="经济学" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>读书笔记：亲密关系——通往灵魂的桥梁</title>
    <link href="https://v-swye.github.io/kanaeba/2019/08/11/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E4%BA%B2%E5%AF%86%E5%85%B3%E7%B3%BB%E2%80%94%E2%80%94%E9%80%9A%E5%BE%80%E7%81%B5%E9%AD%82%E7%9A%84%E6%A1%A5%E6%A2%81/"/>
    <id>https://v-swye.github.io/kanaeba/2019/08/11/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E4%BA%B2%E5%AF%86%E5%85%B3%E7%B3%BB%E2%80%94%E2%80%94%E9%80%9A%E5%BE%80%E7%81%B5%E9%AD%82%E7%9A%84%E6%A1%A5%E6%A2%81/</id>
    <published>2019-08-11T03:53:57.000Z</published>
    <updated>2019-09-22T06:35:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>这本来是一本朋友让推荐给日常吵架的室友男朋友的书，因为朋友说的有点意思，又是KU的免费书，便先趁实习摸鱼一睹为快了。从出生起就以血缘与爱紧紧关联的父母家人，到儿时玩伴，到成人后的社交圈和伴侣，我们一生中会遇见无数的人，或紧或松，总是有一根人际的线牵连着。有时，这些错综的线条仿佛编织出一张蹦床，我们可以像孩子一样在上面尽情玩耍；而另一些时候，丝线却从四面八方逼近，直至窒息。反思过去的二十多年，即使经历了许多失败的人际交往，也只能从经验教训中勉强维持少数的成功硕果。学习能力仿佛在人际关系面前大幅折旧，但同时也意味着，这个社会几乎没有教授我们如何爱这个世界。<br>克里斯多福的这本《亲密关系：通往灵魂的桥梁》打开了一扇窗。</p><h2 id="亲密关系的四个阶段"><a href="#亲密关系的四个阶段" class="headerlink" title="亲密关系的四个阶段"></a>亲密关系的四个阶段</h2><p>亲密关系被归纳为四个阶段：月晕——幻灭——内省——启示。除了血缘，大部分时候我们都因月晕而被对方吸引，在甜蜜的幻象后发觉真实而幻灭，认清事实后回归内省，而成功的内省者将有机会获得新的启示，迈向更自由的灵魂。</p><h3 id="月晕"><a href="#月晕" class="headerlink" title="月晕"></a>月晕</h3><p>情感大多始于需求。基于这一自私的动机，我们会被看上去最能满足需求的人吸引，这种“吸引磁场”营造出一种“月晕”的感觉，对方所有的缺点似乎都被掩饰掉，只剩下光鲜亮丽的，被我们所需求和追逐的优点。<br>客观的说，与任何一个人最开始的相识意愿都起源于某种需求。在学风很一般的艺体类初中，我和好友刚开始做朋友的原因几乎是为了享受对方的崇拜；而到了大学，周围有太多优秀的人，而一开始去接近我现在的挚友的原因是单纯的功利：我想知道这么优秀的人是怎么学习的。为什么我的淑芬小测只有67，而别人接近满分？<br>月晕阶段是美好而不切实际的。当我们充分认识到对方所有的好处，就会想要渴求更多，然而“对方却该死地不满足我们？”在激情的浪潮减退时，望着碳酸钙满地的狼藉海滩，一种反差的幻灭几乎是当头一击。</p><h3 id="幻灭"><a href="#幻灭" class="headerlink" title="幻灭"></a>幻灭</h3><p>当需求无法得到满足时，幻灭的感觉让我们不由自主地指责对方。在这个阶段，人们常常会有四种偏差行为，而这些偏差行为与儿时的行为并无太大差别：</p><ul><li>引起注意</li><li>权力斗争</li><li>报复</li><li>自我放弃</li></ul><p>我们常常活在没有被爱的恐惧中。引起对方的注意常常是证明自己被爱最直接的方式，然而可惜的是，哪怕是我们自己也很少能做到24小时全天候只将目光留在自己身上。当引起注意的期望落空，权力斗争（也就是争吵）和报复也就找上门来了。我记得大二时和海参吵架最厉害的一次，就是因为我觉得她只每天在寝室睡觉、翘课，一点也不像我想象中那样大佬的样子；而且动不动就因为要看游泳比赛而好几个小时无视我的QQ消息。之后，我们开始了长达半个月的冷战，删好友、见面就是冷哼——现在想想真是幼稚得可笑——斗争和报复心萦绕在我们俩中间，我觉得她自我中心，而她觉得我不可理喻。</p><blockquote><p>报复的倾向，在权力斗争刚开始的时候就会出现。你会刻意伤害对方，从而减轻自己的痛苦。在报复的时候，你会得到一种冷冰冰的快感，但这种行为很快就会让人上瘾。<br>想要知道你和伴侣的互动中是否夹杂着报复，是有迹可循的。当你觉得伴侣的行为是想伤害你的感情，当你觉得伴侣的话或举动让你受到刺激、背叛或侮辱，那么很可能你们之间的权力斗争已经转变为报复。如果你因为伴侣的痛苦而沾沾自喜，甚至十分高兴的话，那么你就是在报复对方。</p></blockquote><p>在权力斗争的过程中，我们会在正方和反方中自动挑一个合适的角色，而对方就会自然去扮演另一个角色。反方总是在发现问题、挑剔、对正方敷衍的态度步步紧逼，而正方则尝试解决问题、又同时觉得反方有些过于神经质、倾向于逃避。而且，正反方的角色并不是一成不变的，只要能造成对立的局面，双方自然会主动“配合”。<br>而当争吵无力、报复不起作用时，大多数关系的结局都是自我放逐，也是最使人衰弱的偏差行为。放弃努力，或是离开。许多亲密关系大约就终结在这个阶段。</p><h3 id="内省"><a href="#内省" class="headerlink" title="内省"></a>内省</h3><p>在两周的反思后，我向海参诚恳地道歉，而她也哭着发来“抱抱”的表情。不过，别急——幻灭之后的内省并不轻松。被害者监牢的魔咒才刚刚生效——被害者、迫害者和拯救者，三种角色在我们身上可以进行多种排列组合，尝试将我们牢牢锁在自己构筑的牢笼里。</p><blockquote><p>在所有挑战中，“受害者监牢”的三个层面都会存在。人们会扮演你在戏剧三角形中的角色，这反映出由你的心智所创造的陷阱。有时候你会扮演迫害者，用理直气壮的愤怒来攻击伴侣。有时候你会分饰拯救者和迫害者两角，试着用“野蛮的爱”把你的受害者伴侣从困境中解救出来。或者你也可能扮演拯救者，尽一切力量去鼓舞你的受害者伴侣。有时候你会变成受害者，向你的拯救者伴侣求救，但伴侣突然失去了耐心，转换成迫害者的角色。还有些时候，你扮演的受害者会一面求救，一面却又拒绝接受帮助。</p></blockquote><p>但如果你能了解，监牢中的这三个角色都是你内心所创造出来的，那么你就能不再扮演受害者。这样你就能明白，你自己就是问题的原因。</p><h3 id="启示"><a href="#启示" class="headerlink" title="启示"></a>启示</h3><p>最后，寻求真理的灵魂将自然送给我们启示，以及崭新的亲密关系——灵魂关系。我认为，这种启示源自一种终于脱离将需求绑定在对方身上之后的独立感。我所寻求的需求，我可以独立从自己身上获得，而无需去强加在别人身上。控制别人的难度远高于对自身进行把握，而如果对方向我们示好，做出一些令人感动的举动，那只是对方的无私付出，我们只需微笑接受，但切记，不要把这种付出当做理所当然，也不要为付出与自己需求之间的差距和不一致而恼怒不已。能满足自己需求的只有自己的努力，我感激对方的陪伴，但也知道从不相欠。<br>说起来也许有些自大，但我与此生的挚友之间所经历的，已幸运地获得了启示。我们已相识五年有余，依然能保持极其良好和谐的交流，明明大部分时间都是网友，却像从未离开一般。</p><h2 id="问题的根源"><a href="#问题的根源" class="headerlink" title="问题的根源"></a>问题的根源</h2><p>亲密关系的四个阶段随有时间先后，但终归其根源是无法从时间维度上进行割裂的。出现问题的一直是我们自己，而这种问题的起源从儿时的经历就开始积累产生了。在本书中，令我印象最深刻的问题分别是：痛苦、期望、投射、死忠和竞争。</p><h3 id="逃避痛苦"><a href="#逃避痛苦" class="headerlink" title="逃避痛苦"></a>逃避痛苦</h3><p>需求不被满足让我们感受痛苦，但比起受苦，大多数人会觉得逃避来的容易得多。比如，在幻灭阶段，要超脱自己的痛苦需要很大的努力，但借着报复来转移注意力却很简单。知道对方和自己一样痛苦，心里就会舒服一点。逃避痛苦、不愿面对的倾向，只会延长我们所受的考验与苦难。许多人在面对痛苦时都倾向于逃避、挣扎、发怒或反应过度，因而使痛苦加剧。<br>但是，逃避往往不能解决最根本的问题，痛苦始终在那里，逃避只是在拖延时间。我们需要记住的是，痛苦虽不能避免，要不要受苦却可以选择。尽可能坦然地面对痛苦和内心的冲突，尝试能用勇敢的、灵魂所启发的方式来响应。我想，这种勇敢不仅让我们内心变得更加强大，更会自发地散发一种魅力和气场，潜在地影响周围的他人，而这种正反馈会把我们带入更有响应力的氛围。</p><h3 id="期望与控制"><a href="#期望与控制" class="headerlink" title="期望与控制"></a>期望与控制</h3><p>没有期望就没有失望。月晕阶段让我们对对方不断地添加各种期望，希望将对方改造成自己想要的“人设”。但是，完全心意相通并且愿意按照他人所想行动的人是不可能存在的。正如我们自己是独立的一般，对方也是独立的个体，即使有所关联依赖，仍不会改变我们各自为人的本质。想要控制他人的想法不仅不切实际，且仅仅是延续了“吸引磁场”的自私——真正爱对方，就是要给自己和对方充分的自由。</p><h3 id="投射与阴影人物"><a href="#投射与阴影人物" class="headerlink" title="投射与阴影人物"></a>投射与阴影人物</h3><p>克里斯多福显然是荣格的粉丝。虽然我未曾读过荣格，却大约了解一些基本理念。比如，经典JRPG作品《女神异闻录》就是基于荣格的“人格面具”理念展开，探讨面具下真实自我的发掘之旅。在本书中，作者谈到的投射主要有两种类型：人自身在时间维度上的过去到现在的投射，和将自己的内心世界与所看见的事物绑定的投射。<br>人自身的投射，基本上是把过去的创伤投射至未来。这种投射对我们施加自我局限，产生怀疑，而这种怀疑常常阻挡我们做出一些“冒险却富有创新精神”的行为。而对他人的应用更是广泛：基本上，我们对别人的意见，是在观察他的行为，并用自己的想法诠释之后所形成的。我们对别人行为举止的诠释，都只不过是把我们对自己的评价及信念投射出来罢了。<br>“阴影人物”是一个具备你自身最糟糕特质的人。在内省的时候，如果你没有决心，你心中负面的部分就会投射到你外在的亲密关系中。你的伴侣会自然而然地接收你心中丑恶的事物。然后你就只剩下这几个选择：逃避这些丑恶的事物、试着毁灭它们，或把它们从你生命中排除掉。阴影人物所具备的某些负面特质，是你拒绝承认自己拥有的特质，你甚至会完全否认有这些特质的存在。但是，阴影就是我们自己。</p><h3 id="对家庭的死忠"><a href="#对家庭的死忠" class="headerlink" title="对家庭的死忠"></a>对家庭的死忠</h3><blockquote><p>在工作中，我遇到过一些身为医生、律师、银行家和政客的人，他们投身于各自的行业，纯粹是顺从家人的期望。我也遇到过另外一些同样做这些行业的人，他们的动机是自己的兴趣。在心灵的平静与真正的成功这方面，这两种人有天壤之别。但是，谁比较爱自己的家庭呢？自由选择职业的那些人，往往跟家人处得比较好，也比较感激家人。而那些依家人期望而选择职业的人，对家人的感情则比较含糊不明。</p></blockquote><p>当我看到这句话时，我实在是太赞同了！但是，选择终究是自己做出的，一味去埋怨自己的家人，则又落入了幻灭和内省的怪圈。我们要排除的不是家庭，而是自己无意识中对家庭产生的死忠行为：死忠让人根据固定的模式来行动。我曾认为我是家庭中常年反抗不息的那个，不会轻易受家庭的影响，然而，“当一个人与某件事物对抗时，这件事在你的心里就会变得更加强大”——克里斯多福，你可以嘴下留情一些。我们面对一件事的第一反应通常都是过去数十年来自家庭的潜移默化的影响，此时要做的也许只是保持一些警惕心：灵魂是不受任何不真实的忠诚的束缚的。在面对重大抉择时，还要相信第一反应吗？</p><blockquote><p>要怎样才能知道你是不是被死忠的观念所限制呢？方法很简单：如果你没有表达出你真正的天赋；如果你所做的事没有创意，也没有受到启发；或者，如果你处理事情的方式是不经思考就做出的选择，那么你就很可能本着对家庭的死忠，用代代相传的方法在做事。</p></blockquote><h3 id="竞争"><a href="#竞争" class="headerlink" title="竞争"></a>竞争</h3><blockquote><p>造成竞争的根源是“不足”——也就是相信没有足够的资源可以分给每个人。如果你相信这种想法，又希望自己特别，那么你就会以这种“不足”的观点来看整个世界，因而觉得没有足够的爱可以分给你，所以你必须打败其他竞争者才能得到你所需要的东西。</p></blockquote><p>竞争源于不足感。在社会资源稀缺的中国，我向来对这种恶意的竞争深恶痛绝，即使我是竞争中的获胜方，也难敌不知道什么时候就会向我袭来的一种“可能会落后”的恐惧。然而，即使物质资源是有限的，精神资源却很难说是有限的。在建立各种各样的人际关系时，要注意不被这种自己想象出来的不足感打倒。或者，至少要相信自己内心世界关于爱的资源已经足够挥霍，成功的关系首先始于以最大的爱意包容自己，然后惠及他人。</p><h2 id="阶段的突破与往复"><a href="#阶段的突破与往复" class="headerlink" title="阶段的突破与往复"></a>阶段的突破与往复</h2><h3 id="突破的解决方法"><a href="#突破的解决方法" class="headerlink" title="突破的解决方法"></a>突破的解决方法</h3><p>每一种问题因子都有它的解决方法。首先，确保自己说出的话完全真实。也就是说，只描述自己的情绪，却不把别人当成该负责的对象。要知道，产生这种情绪的责任应当在自己，能对自己的情绪百分之百负责，才能避免以批判对方而进行自我防卫。时刻保持一种清醒的意识，那就是当务之急是解决问题，而非任由自己的短暂情绪对双方施加不必要的压力。最后，不要提醒自己是在牺牲，或是因对方的牺牲而产生罪恶感。真心实意的付出，只需要真心实意的接受。<br>而要做到以上所有点，其实只要做到一点也就够了：无论待人还是待己，永远以充满爱的温柔目光。</p><h3 id="阶段的往复"><a href="#阶段的往复" class="headerlink" title="阶段的往复"></a>阶段的往复</h3><p>要小心的是，亲密关系并不会走完四个阶段就皆大欢喜。有时，我们一瞬间就能抵达最终目的地；有时，我们又在迷雾中跌跌撞撞，绕了好大的圈，却又回到了起点。回到起点也完全无需气馁，每一次周转都是获得新的启示的机会。</p><blockquote><p>每当我们学习到真正重要的事物时，我们就是得到了启示。</p></blockquote><h2 id="最终目标"><a href="#最终目标" class="headerlink" title="最终目标"></a>最终目标</h2><p>对于本书的后半部分，我认为在二十多岁的年龄看来实在是略微玄乎。更实际的感受是，我们应当寻求独立的自我，同时欣赏他人的独立灵魂。独立并不意味着无法联结，只是这种联结不是强迫和想象的，而应当是自然而然的付出与接受，自然而然地完成互补和共同进步。</p><blockquote><p>到最后，你与每一个人的相遇都会成为神圣的邂逅，因为你可以从别人身上发现真正的自己。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这本来是一本朋友让推荐给日常吵架的室友男朋友的书，因为朋友说的有点意思，又是KU的免费书，便先趁实习摸鱼一睹为快了。从出生起就以血缘与爱紧紧关联的父母家人，到儿时玩伴，到成人后的社交圈和伴侣，我们一生中会遇见无数的人，或紧或松，总是有一根人际的线牵连着。有时，这些错综的线条
      
    
    </summary>
    
    
      <category term="读万卷书" scheme="https://v-swye.github.io/kanaeba/categories/%E8%AF%BB%E4%B8%87%E5%8D%B7%E4%B9%A6/"/>
    
    
      <category term="心理" scheme="https://v-swye.github.io/kanaeba/tags/%E5%BF%83%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>预测与解释：统计建模的两面</title>
    <link href="https://v-swye.github.io/kanaeba/2019/08/04/%E9%A2%84%E6%B5%8B%E4%B8%8E%E8%A7%A3%E9%87%8A%EF%BC%9A%E7%BB%9F%E8%AE%A1%E5%BB%BA%E6%A8%A1%E7%9A%84%E4%B8%A4%E9%9D%A2/"/>
    <id>https://v-swye.github.io/kanaeba/2019/08/04/%E9%A2%84%E6%B5%8B%E4%B8%8E%E8%A7%A3%E9%87%8A%EF%BC%9A%E7%BB%9F%E8%AE%A1%E5%BB%BA%E6%A8%A1%E7%9A%84%E4%B8%A4%E9%9D%A2/</id>
    <published>2019-08-04T02:54:49.000Z</published>
    <updated>2019-08-11T05:13:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文为<a href="https://towardsdatascience.com/predicting-vs-explaining-69b516f90796" target="_blank" rel="noopener">Predicting vs. Explaining</a>的阅读笔记。</p><h2 id="预测还是解释？"><a href="#预测还是解释？" class="headerlink" title="预测还是解释？"></a>预测还是解释？</h2><h3 id="Chomsky与Norvig之争"><a href="#Chomsky与Norvig之争" class="headerlink" title="Chomsky与Norvig之争"></a>Chomsky与Norvig之争</h3><p>现代语言学之父Noam Chomsky（乔姆斯基）认为，当前诸如准确率等对成功的自然语言处理的定义并不是科学。将大量文本语料库扔进复杂机器的过程仅仅是在对未分析数据进行近似，却不能真正理解语言。科学的主要目标，应当是发现可解释系统如何运作的原理，而实现目标的正确手段是“让理论指导实践”，即通过精心设计的实验，去除无关的杂音和干扰，从而抽象出系统的本质。<br>另一方面，谷歌研究总监Peter Norvig则并不在意所谓的“科学性”。他认为，基本上语言处理中的所有主要应用都采用了经过训练的概率模型，理由很简单——它们比基于理论或是逻辑规则的老方法表现好得多。用更讽刺的话说，概率模型每年创造数十亿美元的收益，而乔姆斯基的理论追随者却只能贡献不到百万美金的收益。</p><h3 id="统计建模的两个方向"><a href="#统计建模的两个方向" class="headerlink" title="统计建模的两个方向"></a>统计建模的两个方向</h3><p>Leo Breiman指出，统计建模一直都有两种“背道而驰”的文化。</p><ul><li>数据建模派：假设自然是一个黑箱，变量之间随机关联，而<strong>建模的目的就是找到拟合关联性的最佳模型</strong>。</li><li>算法建模派：黑箱中的关联性过于复杂，无法用简单的模型去描述和拟合，<strong>建模的目的是使用算法来尽可能基于输入值来估计和预测输出值</strong>，而并不关心变量之间的关联性该如何理解。<br>很显然，Peter就是坚定的第二种。在复杂系统（如自然语言）面前，“我们应该停止以找到极度优雅的理论解释为目标，转而拥抱这种高度复杂性，并且与我们最好的伙伴——无比有效的数据——一同合作。”</li></ul><h2 id="预测-vs-因果推断"><a href="#预测-vs-因果推断" class="headerlink" title="预测 vs 因果推断"></a>预测 vs 因果推断</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><h4 id="预测建模"><a href="#预测建模" class="headerlink" title="预测建模"></a>预测建模</h4><p>预测建模的目标是给定X，尽可能准确地找到Y的估计值：$\hat Y = \hat {f(x)}$<br>显然，我们的估计值不可能与真实值完全一致，估计值与真实值之间的差距就形成了预测误差。常见的预测误差定义为$E(Y-\hat Y)^2 = E[f(x)+\epsilon - \hat {f(x)}]^2 = E[f(x)-\hat {f(x)}]^2 + var(\epsilon)$，即可进一步拆分为可降低误差和不可降低误差$var(\epsilon)$。于是，预测建模的目标的数学形式就转换为最小化可降低误差部分。</p><h4 id="推断建模"><a href="#推断建模" class="headerlink" title="推断建模"></a>推断建模</h4><p>推断建模的目标是理解X和Y之间的关系，例如：$\Delta X-&gt; \Delta Y?$<br>推断建模一般都使用参数方法（parametric methods）。参数方法指的是首先假设函数f的函数形式，然后通过估计假设的参数来估计函数f。建模的基本步骤为：</p><ol><li>假设f的函数形式</li><li>使用数据来拟合模型</li></ol><p>在第一步中，函数f的形式一般都是线性的。这是因为为了理解X和Y的关系，我们必须在准确模拟二者关系和能解释二者关系之间进行权衡，而线性模型一般能在不过于牺牲拟合性质的情况下提高模型的可解释性。</p><h4 id="因果识别-反事实推理（causal-identification-counterfactual-reasoning）"><a href="#因果识别-反事实推理（causal-identification-counterfactual-reasoning）" class="headerlink" title="因果识别/反事实推理（causal identification/ counterfactual reasoning）"></a>因果识别/反事实推理（causal identification/ counterfactual reasoning）</h4><p>要如何识别因果性？理想情况下，随机试验（例如A/B testing）中我们可以假设treatment的各组之间除了是否接受treatment以外，其他性质在平均意义上是一样的，这就消除了其他变量对Y的影响，Y的所有变动都来源于X。<br>但现实一般充满了各种复杂性，特别是在无法真正做实验的社会科学领域。社科研究通常使用可观测数据（observational data）来估计X对Y的影响，而为了排除其他变量的影响，研究X和Y之间的因果关系，相关学者发明了一系列的识别方法（identification techniques，详见下一篇JEP因果推断阅读笔记）。</p><h3 id="预测占优的现实"><a href="#预测占优的现实" class="headerlink" title="预测占优的现实"></a>预测占优的现实</h3><p>尽管学术界依然推崇因果推断和理论逻辑上的简洁有效，业界占大头的依然是算法建模派。这不仅仅是预测模型在可得商业收益上表现的更好，更是因为衡量一个预测模型是否成功的标准比起因果推断简单得多（例如准确率、精确率、召回率和F1分数）。<br>但同时，也许我们也需要反思：是否过于强调预测性，而忽视了逻辑和解释性上的进步？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为&lt;a href=&quot;https://towardsdatascience.com/predicting-vs-explaining-69b516f90796&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Predicting vs. Explainin
      
    
    </summary>
    
    
      <category term="编程与技术" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数理统计" scheme="https://v-swye.github.io/kanaeba/tags/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>泊松分布笔记：理解与推导</title>
    <link href="https://v-swye.github.io/kanaeba/2019/06/27/%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%90%86%E8%A7%A3%E4%B8%8E%E6%8E%A8%E5%AF%BC/"/>
    <id>https://v-swye.github.io/kanaeba/2019/06/27/%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%90%86%E8%A7%A3%E4%B8%8E%E6%8E%A8%E5%AF%BC/</id>
    <published>2019-06-27T10:51:48.000Z</published>
    <updated>2019-06-30T01:36:18.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://medium.com/@aerinykim/poisson-distribution-intuition-and-derivation-1059aeab90d" target="_blank" rel="noopener">reference</a></p><h2 id="为什么创造泊松分布？"><a href="#为什么创造泊松分布？" class="headerlink" title="为什么创造泊松分布？"></a>为什么创造泊松分布？</h2><p>因为要预测未来<strong>一段时间</strong>内事件<strong>发生K次</strong>的概率。<br>有这种需求，第一个映入我们脑海的，想必通常都是二项分布。</p><h3 id="从二项分布开始"><a href="#从二项分布开始" class="headerlink" title="从二项分布开始"></a>从二项分布开始</h3><p>来看一个二项分布的概率公式：</p><script type="math/tex; mode=display">P(X=k) = C_n^k p^k (1-p)^{n-k}</script><p>其中，<br>n对应“一段时间”：在一段时间内，我们可以进行n次试验（trial）<br>k对应“发生k次”：在n次试验所代表的一段时间中，事件成功发生的次数<br>p：对应<strong>每次试验</strong>中事件发生的概率（时间点而非时间段的视角是之后讨论泊松分布的关键）<br>由此可以看出，要用二项分布模型估计事件发生的概率，至少需要知道两个参数：试验总次数n和单次试验中事件发生的概率p。</p><h4 id="二项分布的基本假设"><a href="#二项分布的基本假设" class="headerlink" title="二项分布的基本假设"></a>二项分布的基本假设</h4><ol><li>事件之间相互独立</li><li>每次试验（trial）只会有<strong>两种</strong>结果：成功（发生），1；或是不成功，0</li><li>每次试验中，成功的概率不变（constant）</li></ol><p>这几个假设中，1和3同样对泊松分布有约束，而2则是发明泊松分布的关键动机。</p><h4 id="二项分布的性质"><a href="#二项分布的性质" class="headerlink" title="二项分布的性质"></a>二项分布的性质</h4><p>在统计特征上，至少关注一阶矩（期望）和二阶矩（方差）。二项分布的期望和方差分别为：</p><script type="math/tex; mode=display">E(X)=np, var(X) = np(1-p)</script><p>推导：对于单次试验，有期望和方差</p><script type="math/tex; mode=display">\mu = 1·p+0·(1-p) = p, \sigma^2 = p·(1-p)^2+(1-p)(0-p)^2 = p(1-p)(1-p+p) = p(1-p)</script><p>再由相互独立假设及期望/方差求和性质可得。</p><p>另一方面，我们也可以关注一些“几何特征”，例如对称性。一般而言，二项分布是右偏而非对称的（除非p=0.5），但随着n增大，分布的的偏度下降，接近正态分布$N(np,np(1-p))$（示例见下图）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> binom,norm</span><br><span class="line">%matplotlib inline</span><br><span class="line">sns.set(style=<span class="string">'darkgrid'</span>, color_codes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">genBinomialDist</span><span class="params">(n,p,ax,size=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    data_binom = binom.rvs(n,p,size = size)</span><br><span class="line">    sns.distplot(data_binom, kde = <span class="literal">False</span>,hist_kws =      &#123;<span class="string">'linewidth'</span>:<span class="number">1</span>,<span class="string">'width'</span>:<span class="number">0.5</span>&#125;,fit = norm,fit_kws = &#123;<span class="string">'color'</span>:<span class="string">'r'</span>,<span class="string">'label'</span>:<span class="string">'norm'</span>&#125;,ax =ax)</span><br><span class="line">    ax.set(xlabel = <span class="string">'number of events'</span>,ylabel = <span class="string">'density'</span>,title = <span class="string">'Binomial Distribution: n = &#123;0&#125;, p = &#123;1&#125;'</span>.format(n,p))</span><br><span class="line">    ax.legend()</span><br><span class="line"></span><br><span class="line">fig,axes = plt.subplots(<span class="number">2</span>,<span class="number">2</span>,figsize = (<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.subplots_adjust(wspace =<span class="number">0.2</span>, hspace =<span class="number">0.4</span>)</span><br><span class="line">genBinomialDist(<span class="number">10</span>,<span class="number">0.2</span>,axes[<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line">genBinomialDist(<span class="number">10</span>,<span class="number">0.5</span>,axes[<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">genBinomialDist(<span class="number">20</span>,<span class="number">0.2</span>,axes[<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">genBinomialDist(<span class="number">50</span>,<span class="number">0.2</span>,axes[<span class="number">1</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p><a href="https://imgchr.com/i/ZlTvP1" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/06/30/ZlTvP1.png" alt="ZlTvP1.png"></a></p><h4 id="二项分布的和"><a href="#二项分布的和" class="headerlink" title="二项分布的和"></a>二项分布的和</h4><p>假设X和Y相互独立，且$X~B(n,p),Y~B(m,p)$，则X+Y也服从二项分布：$X+Y~B(n+m,p)$<br>(X和Y相互独立，p又相同-&gt;可以看做一个n+m次试验下服从二项分布的事件Z，P(X+Y)=P(X)+P(Y))</p><h3 id="二项分布的局限性与泊松分布"><a href="#二项分布的局限性与泊松分布" class="headerlink" title="二项分布的局限性与泊松分布"></a>二项分布的局限性与泊松分布</h3><p>如之前所述，二项分布的基本假设第二条要求每次试验只能有两个结果，而每次试验的发生都需要时间——对于离散模型，大多数时候，我们可以把观测n次试验的时间段分割成多个更短的时间段，从而保证每个时间段里只有一次试验发生，并且结果仅为成功事件或是不成功事件。然而，在某些时候我们必须把时间段划分得足够小——例如，如果你的文章被大V转发，可能在一分钟内会有多次点赞，这样将单位时间段定义为一分钟就不够满足假设要求了：那么，一秒呢？一毫秒呢？甚至，取一个极限？</p><p>当把时间段无限分割、从而逼近时间点时，二项分布就开始向泊松分布进发了。这时，n-&gt;无穷，与此对应，我们知道二项分布的期望是np，为保证np收敛，p-&gt;0，$np = \lambda$——由此，我们避免再对n和p进行讨论，而只需关注一个参数$\lambda$。</p><h3 id="从二项分布推导泊松分布"><a href="#从二项分布推导泊松分布" class="headerlink" title="从二项分布推导泊松分布"></a>从二项分布推导泊松分布</h3><p>本节将从纯数学的角度推导泊松分布的概率公式。<br>对二项分布而言，我们知道：</p><script type="math/tex; mode=display">P(X=k) = C_n^k p^k (1-p)^{n-k}</script><p>对n取极限，令$p = \lambda/n$，有：</p><script type="math/tex; mode=display">P(X = k) = \lim_{n->\infty} \frac{n!}{(n-k)!k!}(\lambda/n)^k(1-\lambda/n)^{(n-k)}</script><script type="math/tex; mode=display">P(X = k) = \lim_{n->\infty} \frac{n!}{(n-k)!k!}*(\lambda/n)^k*e^{-\lambda}</script><script type="math/tex; mode=display">P(X = k) = \lim_{n->\infty} \frac{n(n-1)···(n-k+1)}{n^k}*\lambda^k*e^{-\lambda}/{k!}</script><p>当n趋近无穷时，$\frac{n(n-1)···(n-k+1)}{n^k}$趋近1。因此，</p><script type="math/tex; mode=display">P(X = k) =\frac{\lambda^k}{k!}e^{-\lambda}</script><p>这就是泊松分布的概率公式。</p><h3 id="泊松分布的假设"><a href="#泊松分布的假设" class="headerlink" title="泊松分布的假设"></a>泊松分布的假设</h3><p>由于泊松分布可以看作二项分布的极限情况，泊松分布的假设条件也与二项分布很类似。具体包括：</p><ol><li>单位时间事件的平均发生概率为常数：因此，在使用泊松分布模型时，选择合适的总时间段作为估计目标是有必要的。例如，台风主要在夏季发生，那么在不同季度台风发生的平均概率是不一样的，选择用泊松分布来模拟每年的台风发生率更科学。</li><li>事件之间相互独立（对应二项分布的假设1）</li></ol><h3 id="泊松分布的性质"><a href="#泊松分布的性质" class="headerlink" title="泊松分布的性质"></a>泊松分布的性质</h3><p>统计性质：<br>泊松分布的期望值为$\lambda$（对应二项分布中的np），方差也为$\lambda$（对应二项分布中的np(1-p)，注意p趋近0）。<br>图形性质：和二项分布类似，但泊松分布总是非对称且右偏的（毕竟p不可能等于0.5）。当$\lambda$逐渐增大时，泊松分布逐渐逼近正态分布。<br>最后，和二项分布一样，服从泊松分布的随机变量X必然取非负值——事件不可能发生负数次。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> poisson</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">genPoissonDist</span><span class="params">(lbda,ax,size=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    data_poisson = poisson.rvs(lbda,size = size)</span><br><span class="line">    sns.distplot(data_poisson, kde = <span class="literal">False</span>,hist_kws = &#123;<span class="string">'linewidth'</span>:<span class="number">1</span>,<span class="string">'width'</span>:<span class="number">0.5</span>&#125;,fit = norm,fit_kws = &#123;<span class="string">'color'</span>:<span class="string">'r'</span>,<span class="string">'label'</span>:<span class="string">'norm'</span>&#125;,ax =ax)</span><br><span class="line">    ax.set(xlabel = <span class="string">'number of events'</span>,ylabel = <span class="string">'density'</span>,title = <span class="string">'Poisson Distribution: lambda = &#123;0&#125;'</span>.format(lbda))</span><br><span class="line">    ax.legend()</span><br><span class="line">fig,axes = plt.subplots(<span class="number">2</span>,<span class="number">2</span>,figsize = (<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.subplots_adjust(wspace =<span class="number">0.2</span>, hspace =<span class="number">0.4</span>)</span><br><span class="line">genPoissonDist(<span class="number">3</span>,axes[<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line">genPoissonDist(<span class="number">5</span>,axes[<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">genPoissonDist(<span class="number">10</span>,axes[<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">genPoissonDist(<span class="number">40</span>,axes[<span class="number">1</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p><a href="https://imgchr.com/i/ZlTx8x" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/06/30/ZlTx8x.png" alt="ZlTx8x.png"></a></p><h3 id="泊松分布的应用"><a href="#泊松分布的应用" class="headerlink" title="泊松分布的应用"></a>泊松分布的应用</h3><p>满足事件发生相互独立且各个时间段内平均发生次数不变的问题都可以用泊松分布来模拟，例如某客服中心工作日每小时打进来的电话数量。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://medium.com/@aerinykim/poisson-distribution-intuition-and-derivation-1059aeab90d&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;referenc
      
    
    </summary>
    
    
      <category term="编程与技术" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数理统计" scheme="https://v-swye.github.io/kanaeba/tags/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记：回归问题中的常用损失函数</title>
    <link href="https://v-swye.github.io/kanaeba/2019/06/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <id>https://v-swye.github.io/kanaeba/2019/06/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</id>
    <published>2019-06-03T12:26:37.000Z</published>
    <updated>2019-10-24T11:01:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>在经济学的参数估计中，我们常常需要定一个目标函数——既有最大化，比如最大化效用、最大化似然函数（MLE）等，也有最小化的最小二乘法。在机器学习中也通过目标函数施加约束来得到最优模型估计，其中我们把<strong>最小化</strong>的一类函数称为“损失函数”。因此，损失函数选择是否恰当，就成了影响模型预测效果的关键之一。</p><p>根据监督学习的类型，损失函数也可以分为分类问题或回归问题损失函数两类。这里主要笔记回归问题中常见的损失函数以及它们的优缺点。</p><h2 id="L1损失与L2损失"><a href="#L1损失与L2损失" class="headerlink" title="L1损失与L2损失"></a>L1损失与L2损失</h2><h3 id="L1损失"><a href="#L1损失" class="headerlink" title="L1损失"></a>L1损失</h3><p>在机器学习术语中，“L1损失”指的就是平均绝对值误差Mean Absolute Error（MAE）。其计算公式为：</p><script type="math/tex; mode=display">MAE = \frac{1}{n}\sum ^n_{i=1}|y_i-\hat y_i|</script><p>MAE的特色是只衡量误差的模长而不考虑方向。<br>与MSE相比（见下一节L2损失），MAE对异常点更Robust，因为它对误差模长是线性的，并不会对异常点施加更高的惩罚。</p><p>L1损失的Python代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define a function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mae</span><span class="params">(y, yp)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.abs(y-yp)</span><br><span class="line"><span class="comment"># or use sklearn tools</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br></pre></td></tr></table></figure></p><h3 id="L2损失"><a href="#L2损失" class="headerlink" title="L2损失"></a>L2损失</h3><p>L2损失即是大名鼎鼎且最为常用的回归损失函数，也是最小二乘法最核心的思想体现。</p><script type="math/tex; mode=display">MSE = \frac{1}{n}\sum^n_{i=1}(y_i-\hat y_i)^2</script><p>L2损失对误差是二次的，因此当误差大于1时，会赋予异常点更大的权重，因此会使模型倾向于向减小异常点的方向更新。<br>L2损失的Python代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define a function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mse</span><span class="params">(y, yp)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (y-yp)**<span class="number">2</span></span><br><span class="line"><span class="comment"># or use sklearn tools</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_square_error</span><br></pre></td></tr></table></figure></p><h3 id="权衡L1损失与L2损失"><a href="#权衡L1损失与L2损失" class="headerlink" title="权衡L1损失与L2损失"></a>权衡L1损失与L2损失</h3><p>L1和L2损失的对比，在直观上可以通过设定模型$y=a $来理解（即X的所有系数为0，用y对常数项回归）。如果最小化L1损失（MAE），则为使a到所有y值的距离之和最小，a应该取y的中位数（为什么？见下及参考3），有$\hat a = median(y)$。如果最小化L2损失（MSE），则学过计量的都知道这个解就是$\hat a = \overline y$，即y的平均值。<br>那么问题来了：</p><ul><li>为什么最小一乘法下解是中位数？<br>假设我们有一列数，将其按最大最小、第二大第二小两两分组，依次进行下去。现在我们可以衡量某个点到各组两端的距离。对于最大最小组，其距离之和最小的点肯定是两点连线上的任意一点（到两端距离始终等于$y_{max}-y_{min}$），其他组同理，依次缩圈到中央中位数，结束。<br>（不过，对于总数为偶数的数列，解未必是中央两数的平均值，而可以是最中央两数之间任意一点——因此MAE下未必有唯一解）</li><li>为什么最小二乘法下解是平均数？<br>MSE的好处是连续可导，所以简单求导可得。</li></ul><p>回到正题，我们知道中位数的特征就是对异常值不敏感，而平均数则会受异常值影响，这也就是MAE和MSE的区别之一。如果一个数据集，特别是训练数据集中异常值很多，而测试数据集或是现实生活中中异常值很少，那么选择MAE会是比MSE更好的选项，降低对异常值靠近的倾向。而如果需要强调异常点的情况，MSE就能派上用场。<br>但MAE并不万能，首先它不是连续可导的，可能存在多解，对模型估计造成影响；另一方面，特别是对于神经网络而言，MAE的梯度是恒定的（斜率绝对值恒定为1），这就使我们在接近最小值的过程中依然有很大的梯度，不利于学习到最小值点（相当于学习速率$\alpha$很大）。一个解决方案是引入变化的学习率，在损失接近最小值时降低$\alpha$。<br>MSE在神经网络中则可以使用恒定的学习率，这是因为在接近最小值时二次函数的梯度不断减小，结果更加精确。</p><h2 id="Huber损失"><a href="#Huber损失" class="headerlink" title="Huber损失"></a>Huber损失</h2><p>Huber损失又称平滑的平均绝对误差——还记得MAE函数到达最小点处不可导的那个尖头吗？Huber损失的目的就是将这个尖头周围的局域部分平滑成MSE的形式，从而在0点也可微分。</p><script type="math/tex; mode=display">L_\delta(y,f(x)) = 0.5*(y-f(x))^2,for\ |y-f(x)|<\delta; \\OR =\ \delta|y-f(x)|-0.5*\delta^2, otherwise</script><p><img src="https://image.jiqizhixin.com/uploads/editor/47cb7b9a-337b-4766-ad41-7b3a1d7ce0b2/1529558777466.png" alt><br><a href="https://www.jiqizhixin.com/articles/2018-06-21-3" target="_blank" rel="noopener">图片来源，侵删</a><br>在$[-\delta,\delta]$之间时，Huber类似MSE，在之外的区间类似MAE。<br><strong>Huber损失的关键在于超参数$\delta$的定义：这决定了到底多远是异常点。</strong></p><p>Huber损失的Python实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">huber_loss</span><span class="params">(y,yp,delta)</span>:</span></span><br><span class="line">    huber_mse = <span class="number">0.5</span>*（y-yp)**<span class="number">2</span></span><br><span class="line">    huber_mae = delta*(np.abs(y-yp)<span class="number">-0.5</span>*delta)</span><br><span class="line">    <span class="keyword">return</span> np.where(np.abs(y-yp)&lt;delta, huber_mse, huber_mae)</span><br></pre></td></tr></table></figure></p><h2 id="分位数损失与Log-Cosh损失"><a href="#分位数损失与Log-Cosh损失" class="headerlink" title="分位数损失与Log-Cosh损失"></a>分位数损失与Log-Cosh损失</h2><p>这两个损失函数比较高端，目前还没有学到有应用场景的机器学习模型，之后会补上相关内容~</p><h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ol><li><a href="https://www.jiqizhixin.com/articles/2018-06-21-3" target="_blank" rel="noopener">Understanding the 3 most common loss functions for Machine Learning Regression</a></li><li><a href="https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3" target="_blank" rel="noopener">机器学习大牛最常用的5个回归损失函数，你知道几个？</a></li><li><a href="https://yufree.cn/cn/2013/03/31/median/" target="_blank" rel="noopener">最小一乘法的解为什么是中位数？</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在经济学的参数估计中，我们常常需要定一个目标函数——既有最大化，比如最大化效用、最大化似然函数（MLE）等，也有最小化的最小二乘法。在机器学习中也通过目标函数施加约束来得到最优模型估计，其中我们把&lt;strong&gt;最小化&lt;/strong&gt;的一类函数称为“损失函数”。因此，损失
      
    
    </summary>
    
    
      <category term="编程与技术" scheme="https://v-swye.github.io/kanaeba/categories/%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器学习" scheme="https://v-swye.github.io/kanaeba/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据分析" scheme="https://v-swye.github.io/kanaeba/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Econ Espresso 19M5W5</title>
    <link href="https://v-swye.github.io/kanaeba/2019/06/02/Econ-Espresso-19M5W5/"/>
    <id>https://v-swye.github.io/kanaeba/2019/06/02/Econ-Espresso-19M5W5/</id>
    <published>2019-06-02T09:12:39.000Z</published>
    <updated>2019-06-04T13:59:11.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Economist"><a href="#The-Economist" class="headerlink" title="The Economist"></a>The Economist</h2><h3 id="美国枪支大量流入拉丁美洲"><a href="#美国枪支大量流入拉丁美洲" class="headerlink" title="美国枪支大量流入拉丁美洲"></a>美国枪支大量流入拉丁美洲</h3><p>2018年，墨西哥33000件谋杀案中大约一半有美国产枪支的身影。整个拉丁美洲大抵如此。<br>大部分进入墨西哥的美国枪支在美国国内以合法形式购买，经由佛罗里达的港口与其他进口产品一同输入。我们关心的问题是，美国枪支的可得性是否增加了谋杀率？2004年美国强攻击性武器禁令的废止提供了一个自然实验，研究表明，在禁令废止的州附近的墨西哥城市，谋杀率高于那些禁令保持的州附近。<br>不过，走私枪支并不是唯一的问题。拉丁美洲的警方和军方“习惯于枪支丢失”（当然实际上是卖掉了）。</p><h3 id="中国严惩无法偿还债务者"><a href="#中国严惩无法偿还债务者" class="headerlink" title="中国严惩无法偿还债务者"></a>中国严惩无法偿还债务者</h3><p>近年来，中国政府鼓励消费金融。居民债务占GDP比重从2013年的1/3到去年年终接近50%（美国：75%），包含抵押贷款、银行贷款、信用卡、部分线上贷款等，考虑到一些互联网贷款没有被计入官方数字，这一比重可能更高。<br>过去，国内高利贷横行，高利贷的追债人和债务人之间的问题一直是社会热点。随着数字支付的发展，追踪个人支出变得更加容易，信用评估机构的增长也增加了债权人的信心。<br>最近，政府引入了更严格的规定，违约者（个人或公司法人代表）将被记入黑名单：禁止乘飞机或高铁，住豪华酒店或者送他们的孩子上公费学校。<br>personal bankruptcy的建立可能有助于识别和帮助那些真的失去还债能力的人。</p><h2 id="财新"><a href="#财新" class="headerlink" title="财新"></a>财新</h2><h3 id="5月水果狂涨价为哪般"><a href="#5月水果狂涨价为哪般" class="headerlink" title="5月水果狂涨价为哪般"></a>5月水果狂涨价为哪般</h3><p>5月中旬，北京新发地水果批发市场的水果价格总体比去年同期上涨了近80%，个别种类涨幅甚至超过100%。<br>（从最近市面上的苹果等价格也可以看出，以前4-6块一斤的苹果已经上升到8-9块，只有香蕉价格还比较合理）</p><blockquote><p>仍看食用农产品价格指数，香蕉的环比增幅大体表现为上下波动、有正有负的状态，葡萄在5月上旬经历了周环比11.3%的峰值后，已出现了增幅放缓的迹象，而西瓜更是连续降价两周了。</p></blockquote><p>价格影响因素：</p><ul><li>季节性因素：5月为供应淡季，主要靠2018年秋季的存货</li><li>天气因素：三大苹果主产地陕西、山西和山东2017年占全国总量的60%，2018年春天这些地区天气低温时间长，开花时期伴有大风，难以授粉，导致2018年秋天苹果产量明显下滑</li><li>成本性因素：生产环节，务农成本逐渐提高，化肥价格上行，农民工用工荒，土地租金上升；流动环节，运输、储存、经销商↑，人力成本——门店租金，冷链要求等</li></ul><p>预测：不同水果之间的消费具有强替代性，再加上六月份水果价格不会继续保持这种强上升势头<br>但长期看，农业高成本时代到来，水果价格总体水平很可能长期呈现上涨趋势。</p><h3 id="继续推进利率市场化改革"><a href="#继续推进利率市场化改革" class="headerlink" title="继续推进利率市场化改革"></a>继续推进利率市场化改革</h3><p>央行行长易纲在讲话中指出，目前存贷款基准利率处于适度水平，将研究不再公布贷款基准利率。<br>在利率双轨制下，存贷款利率上下限已经放开，但央行依然公布存贷款基准利率供金融企业参考。<br>央行存款基准利率将继续发挥重要作用，而贷款利率实际上已放开，有助于金融机构按照实际风险定价，降低小微企业融资成本，提升融资可得性。<br>所谓“利率两轨”指的是存贷款基准利率和市场化无风险利率并存。<br>目前市场上的指标性利率：SHIBOR，贷款基础利率（LPR），国债收益率曲线。</p><h2 id="日经中文网"><a href="#日经中文网" class="headerlink" title="日经中文网"></a>日经中文网</h2><h3 id="丰田拟出资滴滴加快获取中国出行服务需求"><a href="#丰田拟出资滴滴加快获取中国出行服务需求" class="headerlink" title="丰田拟出资滴滴加快获取中国出行服务需求"></a>丰田拟出资滴滴加快获取中国出行服务需求</h3><p>除了对该公司出资外，还讨论成立涉足移动出行服务的新公司，出资额总计预计达到600亿日元（38亿人民币约）。除了中国，丰田相继投资了世界各地的网约车企业，着力打造出行服务，积极发展推动共享和自动驾驶等新一代技术。</p><h2 id="WSJ-City"><a href="#WSJ-City" class="headerlink" title="WSJ City"></a>WSJ City</h2><h3 id="美国一季度GDP"><a href="#美国一季度GDP" class="headerlink" title="美国一季度GDP"></a>美国一季度GDP</h3><p>美国2019年一季度GDP上涨3.1%，略低于预期。<br>部分投资者预计Fed为刺激经济增长可能会下调利息，但经济学家也声称这种说法过于夸张。</p><h3 id="特朗普宣布提升对墨西哥关税"><a href="#特朗普宣布提升对墨西哥关税" class="headerlink" title="特朗普宣布提升对墨西哥关税"></a>特朗普宣布提升对墨西哥关税</h3><p>特朗普周四宣布准备提升对墨西哥关税，除非该国政府控制该国前往美国南部寻求庇护的移民数量。股市闻声下跌。周五黄金和日元升值，美国国债利率下降。德国基准国债利率达到史低。<br>全球汽车供应链受该关税影响颇深——美、日、欧汽车企业股价均下跌</p><h2 id="日经中文网-1"><a href="#日经中文网-1" class="headerlink" title="日经中文网"></a>日经中文网</h2><h3 id="菲律宾保姆与汇款革命"><a href="#菲律宾保姆与汇款革命" class="headerlink" title="菲律宾保姆与汇款革命"></a>菲律宾保姆与汇款革命</h3><p>蚂蚁金服2018年6月推出的区块链付款大受欢迎，因海外汇款免除了手续费（Western Union小额汇款均收费）。该技术估计整体每年为20万菲佣省1亿港币（每年500），如在全世界普及或可加速人员跨境流动。<br>对东南亚一些外来务工人员很高的国家来说，该技术极大节约了成本。例如，每年从马来西亚等地汇入巴基斯坦的国际汇款约占巴基斯坦GDP的6%。<br>区块链技术也能将现有银行结算系统的速度提升近百倍。</p><p>注：因特殊原因，M6W1停更一周。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;The-Economist&quot;&gt;&lt;a href=&quot;#The-Economist&quot; class=&quot;headerlink&quot; title=&quot;The Economist&quot;&gt;&lt;/a&gt;The Economist&lt;/h2&gt;&lt;h3 id=&quot;美国枪支大量流入拉丁美洲&quot;&gt;&lt;a href
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>数据分析与机器学习中常用的模型评估指数</title>
    <link href="https://v-swye.github.io/kanaeba/2019/05/29/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%95%B0/"/>
    <id>https://v-swye.github.io/kanaeba/2019/05/29/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%95%B0/</id>
    <published>2019-05-29T06:54:45.000Z</published>
    <updated>2019-06-27T10:53:50.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9" target="_blank" rel="noopener">reference</a><br>“如何得到最准确的模型？”<br>“那取决于你用这个模型想解决什么业务挑战。”<br>对数据分析而言，如何评估模型并不是那么简单，也没有唯一的标准。从一般逻辑上看，最直观的衡量方式是准确率（accuracy）：即，在所有样本中，准确预测中（0或1）的比率。<br>不过，在讲清楚准确率和其他模型评估方式之前，首先需要理解一个简单的情景矩阵。</p><h2 id="预测的情景矩阵"><a href="#预测的情景矩阵" class="headerlink" title="预测的情景矩阵"></a>预测的情景矩阵</h2><div class="table-container"><table><thead><tr><th>真实值↓/预测值→</th><th>Positive</th><th>Negative</th></tr></thead><tbody><tr><td>Positive</td><td>TP</td><td>FN</td></tr><tr><td>Negative</td><td>FP</td><td>TN</td></tr></tbody></table></div><p>缩写解释：</p><ul><li>TP：True positive，指预测为真，实际确实为真</li><li>FN：False negative, 指预测为假，但搞错了，实际应该是真</li><li>FP，TN类推。</li></ul><p>回到准确率上，从这个矩阵我们可以将准确率写成更规范的公式，</p><script type="math/tex; mode=display">Accuracy = \frac{TP+TN}{TP+TN+FP+FN}</script><p>从公式中已经可以看出准确率在评估模型上的不足——当（FP+FN）很小时，准确率接近100%，但如果预测错误时带来的损失很大会怎么样？比如，我们要解决一个预测一家大型上市公司未来一年内是否会破产的问题，样本中实际上破产的公司是非常少的，最后模型准确度可能高达99.9%，但如果真的破产了，<strong>FN的成本将会非常高</strong>。在FN或FP的成本很高的情况下，准确率并不是最好的方案。</p><h2 id="其他模型度量方式（metrics）"><a href="#其他模型度量方式（metrics）" class="headerlink" title="其他模型度量方式（metrics）"></a>其他模型度量方式（metrics）</h2><h3 id="精确率与召回率"><a href="#精确率与召回率" class="headerlink" title="精确率与召回率"></a>精确率与召回率</h3><p>有了情景矩阵，计算和理解精确率（Precision）和召回率（Recall）就变得简单了：</p><script type="math/tex; mode=display">Precision = \frac{TP}{TP+FP}</script><script type="math/tex; mode=display">Recall = \frac{TP}{TP+FN }</script><blockquote><p>来自Kanaeba的Tips：要记住二者差别，记住Precision的首字母P——它将出现在分子分母的每个元素里。</p></blockquote><p>二者分子都是TP，即正确预测到真值的情况，区别只在分母上。对精确率而言，其分母指的是所有预测为真的情况；而召回率的分母则强调所有<strong>应当</strong>被预测为真的情况。</p><ul><li>精确率：预测为真时，正确的比率。重视情景矩阵的第一列（啊，我弄错了）</li><li>召回率：在应当被预测为真时做到这一点的比率。重视情景矩阵的第一行。（我本该弄对的）</li></ul><p>我们再与准确率的公式对比，可以看出分子上精确率和召回率都更重视TP的比率，而不再去考虑TN的干扰；分母上这两者也主要探讨与真值有关的情况。相比于准确率，可以说精确率和召回率的天平明显倾向于预测值和真实集中为1的那些部分。</p><ul><li>FP成本高：使用精确率，去掉TN和FN的干扰。例如，识别垃圾邮件（Spam = 1）的问题中，将正常邮件识别成垃圾邮件（FP）是我们最不期望发生的，那么我们就用FP去惩罚。</li><li>FN成本高：使用召回率，去掉TN和FP的干扰。例如之前的破产（破产=1）预测问题，用FN去惩罚。</li></ul><h3 id="F1分数（F1-Score）"><a href="#F1分数（F1-Score）" class="headerlink" title="F1分数（F1 Score）"></a>F1分数（F1 Score）</h3><p>F1 score实质上是精确率和召回率的调和平均值。</p><script type="math/tex; mode=display">\frac{2}{F1} = \frac{1}{P}+\frac{1}{R}</script><p>相比准确率，F1依然不在意TN的值。所以，当我们所研究的问题中样本分类分布极度不平衡（例如，有大量真实为0的值，这也是业务中很常见的情况），而FN和FP的成本又难分伯仲时，F1给我们一个在精确率和召回率之间找到平衡的机会。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>最简单普通的情况：准确率</li><li>FP成本很高：精确率</li><li>FN成本很高：召回率</li><li>分类分布不均衡，FP/FN均有一定成本：F1分数</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;reference&lt;/a&gt;&lt;br&gt;“如何
      
    
    </summary>
    
    
    
      <category term="机器学习" scheme="https://v-swye.github.io/kanaeba/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据分析" scheme="https://v-swye.github.io/kanaeba/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
</feed>
